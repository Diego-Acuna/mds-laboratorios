{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "\n",
        "\n",
        "# **Laboratorio 11: Pienso, luego predigo üí°**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2025</strong></center>\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Diego Cortez, Gabriel Iturra\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6ikgVYzghB"
      },
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados**\n",
        "\n",
        "- Nombre de alumno 1: Diego Acu√±a\n",
        "- Nombre de alumno 2: Tom√°s Ram√≠rez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/Diego-Acuna/mds-laboratorios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUuwsXrKzmkK"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda **fuertemente** asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Resoluci√≥n de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas √∫tiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci√≥n van a usar m√©todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gOcejYb6uzOO"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsecci√≥n es que puedan implementar m√©todos de RL y as√≠ generar una estrategia para jugar el cl√°sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c√≥digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **1.1.1 Descripci√≥n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci√≥n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "El ambiente **Blackjack** de Gymnasium modela una versi√≥n simplificada del juego de Blackjack como un **proceso de decisi√≥n de Markov (MDP)**:\n",
        "\n",
        "- **Estados (S)**  \n",
        "  Cada estado se representa t√≠picamente como una tupla $(\\text{sum\\_jugador}, \\text{carta\\_visible\\_dealer}, \\text{tiene\\_as\\_usable})$, donde:\n",
        "  - `sum_jugador`: suma actual de las cartas del jugador.\n",
        "  - `carta_visible_dealer`: valor (1‚Äì10) de la carta que muestra el dealer.\n",
        "  - `tiene_as_usable`: booleano que indica si el jugador tiene un As que puede contar como 11 sin pasarse de 21.  \n",
        "  Adem√°s, hay estados terminales en los que la mano ya termin√≥ (el episodio se acaba).\n",
        "\n",
        "- **Acciones (A)**  \n",
        "  Normalmente son solo dos:\n",
        "  - `Hit` (pedir carta): el jugador solicita una nueva carta.\n",
        "  - `Stick` (plantarse): el jugador deja de pedir y le toca jugar al dealer (seg√∫n la pol√≠tica fija del ambiente).\n",
        "\n",
        "- **Recompensas (R)**  \n",
        "  Se entregan al final del episodio (cuando el jugador se pasa, se planta y termina la mano, etc.):\n",
        "  - **+1** si el jugador gana.\n",
        "  - **0** si hay empate (*push*).\n",
        "  - **‚àí1** si el jugador pierde.  \n",
        "\n",
        "As√≠, dado un estado (suma actual, carta del dealer, As usable) y una acci√≥n (`hit` o `stick`), el ambiente transiciona aleatoriamente a un nuevo estado seg√∫n las cartas que salen del mazo y al final entrega una recompensa seg√∫n el resultado de la mano.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 5000 veces y reporte el promedio y desviaci√≥n de las recompensas. ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica? ¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9p2PrLLR9yju"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de episodios: 5000\n",
            "Retorno promedio: -0.3890\n",
            "Desviaci√≥n est√°ndar del retorno: 0.8976\n"
          ]
        }
      ],
      "source": [
        "n_episodes = 5000\n",
        "returns = []\n",
        "\n",
        "for ep in range(n_episodes):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "    ep_return = 0.0\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        ep_return += reward\n",
        "        done = terminated or truncated\n",
        "\n",
        "    returns.append(ep_return)\n",
        "\n",
        "returns = np.array(returns)\n",
        "\n",
        "promedio = returns.mean()\n",
        "desviacion = returns.std()\n",
        "\n",
        "print(f\"N√∫mero de episodios: {n_episodes}\")\n",
        "print(f\"Retorno promedio: {promedio:.4f}\")\n",
        "print(f\"Desviaci√≥n est√°ndar del retorno: {desviacion:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con los resultados obtenidos, al usar una pol√≠tica completamente aleatoria en el ambiente de Blackjack y simular $5000$ episodios, se observa un retorno promedio de aproximadamente $-0.3890$ con una desviaci√≥n est√°ndar cercana a $0.8976$. Esto indica que, en promedio, la pol√≠tica pierde alrededor de $0.39$ unidades por mano, lo que es coherente con el hecho de que elegir acciones al azar en Blackjack es claramente desventajoso. Dado que las recompensas t√≠picas son $-1$ cuando se pierde, $0$ cuando hay empate y $+1$ cuando se gana, un valor esperado negativo muestra que se pierden m√°s partidas de las que se ganan.\n",
        "\n",
        "La desviaci√≥n est√°ndar relativamente alta refleja la variabilidad natural del juego: hay episodios ganados, perdidos y empatados, por lo que las recompensas individuales fluct√∫an bastante alrededor del promedio. Sin embargo, al considerar un n√∫mero grande de episodios, el retorno medio negativo permite concluir que esta pol√≠tica aleatoria constituye un baseline pobre, que sirve como referencia m√≠nima. Cualquier agente entrenado posteriormente debiese superar este rendimiento (acercarse a 0 o incluso obtener un promedio positivo) para considerarse efectivo en comparaci√≥n con ‚Äújugar al azar‚Äù."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se concluye que el performance es malo pues el promedio es negativo. Adem√°s, las recompensas obtenidas reflejan que, al jugar al azar, el agente b√°sicamente no explota ninguna estructura del juego, por lo que ganar es casi cuesti√≥n de suerte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m9JsFA1wGmnH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.33     |\n",
            "|    ep_rew_mean     | -0.42    |\n",
            "| time/              |          |\n",
            "|    fps             | 1727     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.33     |\n",
            "|    ep_rew_mean     | -0.42    |\n",
            "| time/              |          |\n",
            "|    fps             | 1727     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.25        |\n",
            "|    ep_rew_mean          | -0.41       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1201        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016728725 |\n",
            "|    clip_fraction        | 0.292       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.677      |\n",
            "|    explained_variance   | -0.127      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.281       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0473     |\n",
            "|    value_loss           | 0.77        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.25        |\n",
            "|    ep_rew_mean          | -0.41       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1201        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016728725 |\n",
            "|    clip_fraction        | 0.292       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.677      |\n",
            "|    explained_variance   | -0.127      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.281       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0473     |\n",
            "|    value_loss           | 0.77        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.22       |\n",
            "|    ep_rew_mean          | -0.16      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1083       |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 5          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01752542 |\n",
            "|    clip_fraction        | 0.254      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.633     |\n",
            "|    explained_variance   | 0.105      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.297      |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0436    |\n",
            "|    value_loss           | 0.735      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.22       |\n",
            "|    ep_rew_mean          | -0.16      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1083       |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 5          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01752542 |\n",
            "|    clip_fraction        | 0.254      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.633     |\n",
            "|    explained_variance   | 0.105      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.297      |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0436    |\n",
            "|    value_loss           | 0.735      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.18      |\n",
            "|    ep_rew_mean          | -0.17     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 1038      |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 7         |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0313946 |\n",
            "|    clip_fraction        | 0.227     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.565    |\n",
            "|    explained_variance   | 0.137     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.308     |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | -0.0381   |\n",
            "|    value_loss           | 0.722     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.18      |\n",
            "|    ep_rew_mean          | -0.17     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 1038      |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 7         |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0313946 |\n",
            "|    clip_fraction        | 0.227     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.565    |\n",
            "|    explained_variance   | 0.137     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.308     |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | -0.0381   |\n",
            "|    value_loss           | 0.722     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.26        |\n",
            "|    ep_rew_mean          | -0.25       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1018        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017013866 |\n",
            "|    clip_fraction        | 0.092       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.511      |\n",
            "|    explained_variance   | 0.151       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.4         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    value_loss           | 0.742       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.26        |\n",
            "|    ep_rew_mean          | -0.25       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1018        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017013866 |\n",
            "|    clip_fraction        | 0.092       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.511      |\n",
            "|    explained_variance   | 0.151       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.4         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    value_loss           | 0.742       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.27        |\n",
            "|    ep_rew_mean          | -0.07       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1008        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007709322 |\n",
            "|    clip_fraction        | 0.0787      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.459      |\n",
            "|    explained_variance   | 0.217       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.31        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0107     |\n",
            "|    value_loss           | 0.691       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.27        |\n",
            "|    ep_rew_mean          | -0.07       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1008        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007709322 |\n",
            "|    clip_fraction        | 0.0787      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.459      |\n",
            "|    explained_variance   | 0.217       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.31        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0107     |\n",
            "|    value_loss           | 0.691       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.31        |\n",
            "|    ep_rew_mean          | -0.21       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1002        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008917006 |\n",
            "|    clip_fraction        | 0.0799      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.428      |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.331       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0115     |\n",
            "|    value_loss           | 0.691       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.31        |\n",
            "|    ep_rew_mean          | -0.21       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1002        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008917006 |\n",
            "|    clip_fraction        | 0.0799      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.428      |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.331       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0115     |\n",
            "|    value_loss           | 0.691       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.38        |\n",
            "|    ep_rew_mean          | -0.13       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 994         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008859264 |\n",
            "|    clip_fraction        | 0.0705      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.386      |\n",
            "|    explained_variance   | 0.196       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.308       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00871    |\n",
            "|    value_loss           | 0.688       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.38        |\n",
            "|    ep_rew_mean          | -0.13       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 994         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008859264 |\n",
            "|    clip_fraction        | 0.0705      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.386      |\n",
            "|    explained_variance   | 0.196       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.308       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00871    |\n",
            "|    value_loss           | 0.688       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.52        |\n",
            "|    ep_rew_mean          | -0.12       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 990         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007991433 |\n",
            "|    clip_fraction        | 0.0669      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.355      |\n",
            "|    explained_variance   | 0.208       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.321       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00951    |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.52        |\n",
            "|    ep_rew_mean          | -0.12       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 990         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007991433 |\n",
            "|    clip_fraction        | 0.0669      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.355      |\n",
            "|    explained_variance   | 0.208       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.321       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00951    |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.39         |\n",
            "|    ep_rew_mean          | -0.13        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 989          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055697295 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.35        |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    value_loss           | 0.695        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.39         |\n",
            "|    ep_rew_mean          | -0.13        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 989          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055697295 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.35        |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    value_loss           | 0.695        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.53        |\n",
            "|    ep_rew_mean          | -0.03       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004617078 |\n",
            "|    clip_fraction        | 0.0616      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.336      |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.332       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00639    |\n",
            "|    value_loss           | 0.708       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.53        |\n",
            "|    ep_rew_mean          | -0.03       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004617078 |\n",
            "|    clip_fraction        | 0.0616      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.336      |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.332       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00639    |\n",
            "|    value_loss           | 0.708       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.35        |\n",
            "|    ep_rew_mean          | -0.07       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 980         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005313797 |\n",
            "|    clip_fraction        | 0.0581      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.315      |\n",
            "|    explained_variance   | 0.22        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00726    |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.35        |\n",
            "|    ep_rew_mean          | -0.07       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 980         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005313797 |\n",
            "|    clip_fraction        | 0.0581      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.315      |\n",
            "|    explained_variance   | 0.22        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00726    |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.48         |\n",
            "|    ep_rew_mean          | 0.15         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 976          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052970173 |\n",
            "|    clip_fraction        | 0.0646       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.3         |\n",
            "|    explained_variance   | 0.22         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.304        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.007       |\n",
            "|    value_loss           | 0.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.48         |\n",
            "|    ep_rew_mean          | 0.15         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 976          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052970173 |\n",
            "|    clip_fraction        | 0.0646       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.3         |\n",
            "|    explained_variance   | 0.22         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.304        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.007       |\n",
            "|    value_loss           | 0.68         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.4         |\n",
            "|    ep_rew_mean          | -0.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006041115 |\n",
            "|    clip_fraction        | 0.0485      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.278      |\n",
            "|    explained_variance   | 0.237       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.419       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00538    |\n",
            "|    value_loss           | 0.659       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.4         |\n",
            "|    ep_rew_mean          | -0.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006041115 |\n",
            "|    clip_fraction        | 0.0485      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.278      |\n",
            "|    explained_variance   | 0.237       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.419       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00538    |\n",
            "|    value_loss           | 0.659       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.31       |\n",
            "|    ep_rew_mean          | -0.09      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 975        |\n",
            "|    iterations           | 15         |\n",
            "|    time_elapsed         | 31         |\n",
            "|    total_timesteps      | 30720      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00375392 |\n",
            "|    clip_fraction        | 0.0386     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.267     |\n",
            "|    explained_variance   | 0.205      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.361      |\n",
            "|    n_updates            | 140        |\n",
            "|    policy_gradient_loss | -0.00435   |\n",
            "|    value_loss           | 0.695      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.31       |\n",
            "|    ep_rew_mean          | -0.09      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 975        |\n",
            "|    iterations           | 15         |\n",
            "|    time_elapsed         | 31         |\n",
            "|    total_timesteps      | 30720      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00375392 |\n",
            "|    clip_fraction        | 0.0386     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.267     |\n",
            "|    explained_variance   | 0.205      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.361      |\n",
            "|    n_updates            | 140        |\n",
            "|    policy_gradient_loss | -0.00435   |\n",
            "|    value_loss           | 0.695      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.41        |\n",
            "|    ep_rew_mean          | 0.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 976         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003679591 |\n",
            "|    clip_fraction        | 0.0429      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.253      |\n",
            "|    explained_variance   | 0.218       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.295       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00456    |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.41        |\n",
            "|    ep_rew_mean          | 0.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 976         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003679591 |\n",
            "|    clip_fraction        | 0.0429      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.253      |\n",
            "|    explained_variance   | 0.218       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.295       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00456    |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.6         |\n",
            "|    ep_rew_mean          | -0.13       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004258126 |\n",
            "|    clip_fraction        | 0.0423      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.238      |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.295       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00457    |\n",
            "|    value_loss           | 0.665       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.6         |\n",
            "|    ep_rew_mean          | -0.13       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004258126 |\n",
            "|    clip_fraction        | 0.0423      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.238      |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.295       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00457    |\n",
            "|    value_loss           | 0.665       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.51        |\n",
            "|    ep_rew_mean          | 0.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003369505 |\n",
            "|    clip_fraction        | 0.0314      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.231      |\n",
            "|    explained_variance   | 0.193       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.283       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0028     |\n",
            "|    value_loss           | 0.689       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.51        |\n",
            "|    ep_rew_mean          | 0.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003369505 |\n",
            "|    clip_fraction        | 0.0314      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.231      |\n",
            "|    explained_variance   | 0.193       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.283       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0028     |\n",
            "|    value_loss           | 0.689       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.35        |\n",
            "|    ep_rew_mean          | -0.17       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 974         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004363293 |\n",
            "|    clip_fraction        | 0.0449      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.213      |\n",
            "|    explained_variance   | 0.181       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00588    |\n",
            "|    value_loss           | 0.703       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.35        |\n",
            "|    ep_rew_mean          | -0.17       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 974         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004363293 |\n",
            "|    clip_fraction        | 0.0449      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.213      |\n",
            "|    explained_variance   | 0.181       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00588    |\n",
            "|    value_loss           | 0.703       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.48         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 972          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050062356 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.191       |\n",
            "|    explained_variance   | 0.209        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.336        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    value_loss           | 0.693        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.48         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 972          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050062356 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.191       |\n",
            "|    explained_variance   | 0.209        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.336        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    value_loss           | 0.693        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.61         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 971          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031506794 |\n",
            "|    clip_fraction        | 0.0344       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.175       |\n",
            "|    explained_variance   | 0.223        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.42         |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.61         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 971          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031506794 |\n",
            "|    clip_fraction        | 0.0344       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.175       |\n",
            "|    explained_variance   | 0.223        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.42         |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.52         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 969          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038946557 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.165       |\n",
            "|    explained_variance   | 0.209        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00412     |\n",
            "|    value_loss           | 0.682        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.52         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 969          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038946557 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.165       |\n",
            "|    explained_variance   | 0.209        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00412     |\n",
            "|    value_loss           | 0.682        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.44         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 970          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036737681 |\n",
            "|    clip_fraction        | 0.0366       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.171       |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.258        |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00358     |\n",
            "|    value_loss           | 0.673        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.44         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 970          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036737681 |\n",
            "|    clip_fraction        | 0.0366       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.171       |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.258        |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00358     |\n",
            "|    value_loss           | 0.673        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | 0.07         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 969          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 50           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033973386 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.15        |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.265        |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00359     |\n",
            "|    value_loss           | 0.655        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | 0.07         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 969          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 50           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033973386 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.15        |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.265        |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00359     |\n",
            "|    value_loss           | 0.655        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.48         |\n",
            "|    ep_rew_mean          | -0.21        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 968          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038774488 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.133       |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.34         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.0041      |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.48         |\n",
            "|    ep_rew_mean          | -0.21        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 968          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038774488 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.133       |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.34         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.0041      |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.55        |\n",
            "|    ep_rew_mean          | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 966         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002996532 |\n",
            "|    clip_fraction        | 0.0411      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.132      |\n",
            "|    explained_variance   | 0.179       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.249       |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00519    |\n",
            "|    value_loss           | 0.678       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.55        |\n",
            "|    ep_rew_mean          | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 966         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002996532 |\n",
            "|    clip_fraction        | 0.0411      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.132      |\n",
            "|    explained_variance   | 0.179       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.249       |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00519    |\n",
            "|    value_loss           | 0.678       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.65         |\n",
            "|    ep_rew_mean          | 0.14         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 967          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 57           |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026793296 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.128       |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.381        |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.65         |\n",
            "|    ep_rew_mean          | 0.14         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 967          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 57           |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026793296 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.128       |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.381        |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019637733 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.12        |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    value_loss           | 0.652        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019637733 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.12        |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    value_loss           | 0.652        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022189533 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.114       |\n",
            "|    explained_variance   | 0.21         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    value_loss           | 0.673        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022189533 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.114       |\n",
            "|    explained_variance   | 0.21         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    value_loss           | 0.673        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.39         |\n",
            "|    ep_rew_mean          | -0.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035707317 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.125       |\n",
            "|    explained_variance   | 0.186        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.324        |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 0.697        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.39         |\n",
            "|    ep_rew_mean          | -0.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035707317 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.125       |\n",
            "|    explained_variance   | 0.186        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.324        |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 0.697        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.63         |\n",
            "|    ep_rew_mean          | -0.02        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 965          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032550078 |\n",
            "|    clip_fraction        | 0.0261       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.111       |\n",
            "|    explained_variance   | 0.228        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 0.656        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.63         |\n",
            "|    ep_rew_mean          | -0.02        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 965          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032550078 |\n",
            "|    clip_fraction        | 0.0261       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.111       |\n",
            "|    explained_variance   | 0.228        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 0.656        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027479131 |\n",
            "|    clip_fraction        | 0.0305       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.101       |\n",
            "|    explained_variance   | 0.175        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.354        |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    value_loss           | 0.698        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027479131 |\n",
            "|    clip_fraction        | 0.0305       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.101       |\n",
            "|    explained_variance   | 0.175        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.354        |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    value_loss           | 0.698        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028056237 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0987      |\n",
            "|    explained_variance   | 0.228        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.355        |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028056237 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0987      |\n",
            "|    explained_variance   | 0.228        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.355        |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033890246 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.091       |\n",
            "|    explained_variance   | 0.167        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    value_loss           | 0.707        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033890246 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.091       |\n",
            "|    explained_variance   | 0.167        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    value_loss           | 0.707        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.47         |\n",
            "|    ep_rew_mean          | -0.23        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013843647 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0827      |\n",
            "|    explained_variance   | 0.207        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.231        |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.000737    |\n",
            "|    value_loss           | 0.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.47         |\n",
            "|    ep_rew_mean          | -0.23        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013843647 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0827      |\n",
            "|    explained_variance   | 0.207        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.231        |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.000737    |\n",
            "|    value_loss           | 0.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.57         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018243571 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0868      |\n",
            "|    explained_variance   | 0.204        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000755    |\n",
            "|    value_loss           | 0.66         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.57         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018243571 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0868      |\n",
            "|    explained_variance   | 0.204        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000755    |\n",
            "|    value_loss           | 0.66         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.3          |\n",
            "|    ep_rew_mean          | -0.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 965          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026073828 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.085       |\n",
            "|    explained_variance   | 0.193        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    value_loss           | 0.675        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.3          |\n",
            "|    ep_rew_mean          | -0.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 965          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026073828 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.085       |\n",
            "|    explained_variance   | 0.193        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    value_loss           | 0.675        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 963          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028873647 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0795      |\n",
            "|    explained_variance   | 0.187        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.387        |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    value_loss           | 0.695        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 963          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028873647 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0795      |\n",
            "|    explained_variance   | 0.187        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.387        |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    value_loss           | 0.695        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.59         |\n",
            "|    ep_rew_mean          | -0.11        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020307864 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0773      |\n",
            "|    explained_variance   | 0.176        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.27         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.000968    |\n",
            "|    value_loss           | 0.715        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.59         |\n",
            "|    ep_rew_mean          | -0.11        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020307864 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0773      |\n",
            "|    explained_variance   | 0.176        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.27         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.000968    |\n",
            "|    value_loss           | 0.715        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031857078 |\n",
            "|    clip_fraction        | 0.0191       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0706      |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031857078 |\n",
            "|    clip_fraction        | 0.0191       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0706      |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.42         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022428525 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0714      |\n",
            "|    explained_variance   | 0.2          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.42         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022428525 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0714      |\n",
            "|    explained_variance   | 0.2          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.61        |\n",
            "|    ep_rew_mean          | 0.12        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 89          |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002142062 |\n",
            "|    clip_fraction        | 0.0224      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0774     |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.356       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    value_loss           | 0.68        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.61        |\n",
            "|    ep_rew_mean          | 0.12        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 89          |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002142062 |\n",
            "|    clip_fraction        | 0.0224      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0774     |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.356       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    value_loss           | 0.68        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.59         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034021942 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0832      |\n",
            "|    explained_variance   | 0.205        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.377        |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.59         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034021942 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0832      |\n",
            "|    explained_variance   | 0.205        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.377        |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.08       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003748633 |\n",
            "|    clip_fraction        | 0.0235      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0727     |\n",
            "|    explained_variance   | 0.202       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.259       |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.000626   |\n",
            "|    value_loss           | 0.674       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.08       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003748633 |\n",
            "|    clip_fraction        | 0.0235      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0727     |\n",
            "|    explained_variance   | 0.202       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.259       |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.000626   |\n",
            "|    value_loss           | 0.674       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.68         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022907075 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0783      |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.301        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000472    |\n",
            "|    value_loss           | 0.671        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.68         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022907075 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0783      |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.301        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000472    |\n",
            "|    value_loss           | 0.671        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.14       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 97          |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002758149 |\n",
            "|    clip_fraction        | 0.025       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0738     |\n",
            "|    explained_variance   | 0.209       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.307       |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.00237    |\n",
            "|    value_loss           | 0.678       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.14       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 97          |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002758149 |\n",
            "|    clip_fraction        | 0.025       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0738     |\n",
            "|    explained_variance   | 0.209       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.307       |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.00237    |\n",
            "|    value_loss           | 0.678       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.58         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019518851 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0688      |\n",
            "|    explained_variance   | 0.194        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.312        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    value_loss           | 0.671        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.58         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019518851 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0688      |\n",
            "|    explained_variance   | 0.194        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.312        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    value_loss           | 0.671        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.14       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006644481 |\n",
            "|    clip_fraction        | 0.0266      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0653     |\n",
            "|    explained_variance   | 0.211       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.368       |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    value_loss           | 0.672       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.14       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006644481 |\n",
            "|    clip_fraction        | 0.0266      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0653     |\n",
            "|    explained_variance   | 0.211       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.368       |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    value_loss           | 0.672       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.47        |\n",
            "|    ep_rew_mean          | -0.08       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 104         |\n",
            "|    total_timesteps      | 100352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004298982 |\n",
            "|    clip_fraction        | 0.023       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0679     |\n",
            "|    explained_variance   | 0.199       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.288       |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0029     |\n",
            "|    value_loss           | 0.69        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.47        |\n",
            "|    ep_rew_mean          | -0.08       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 962         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 104         |\n",
            "|    total_timesteps      | 100352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004298982 |\n",
            "|    clip_fraction        | 0.023       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0679     |\n",
            "|    explained_variance   | 0.199       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.288       |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0029     |\n",
            "|    value_loss           | 0.69        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 106          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032418075 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0702      |\n",
            "|    explained_variance   | 0.216        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.309        |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00098     |\n",
            "|    value_loss           | 0.671        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 106          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032418075 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0702      |\n",
            "|    explained_variance   | 0.216        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.309        |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00098     |\n",
            "|    value_loss           | 0.671        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 108          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039031524 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0686      |\n",
            "|    explained_variance   | 0.183        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.325        |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 108          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039031524 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0686      |\n",
            "|    explained_variance   | 0.183        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.325        |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.45         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 110          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041486872 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.074       |\n",
            "|    explained_variance   | 0.195        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.32         |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 0.692        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.45         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 110          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041486872 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.074       |\n",
            "|    explained_variance   | 0.195        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.32         |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 0.692        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.09       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003254733 |\n",
            "|    clip_fraction        | 0.0236      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0712     |\n",
            "|    explained_variance   | 0.19        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.296       |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00101    |\n",
            "|    value_loss           | 0.684       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.09       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003254733 |\n",
            "|    clip_fraction        | 0.0236      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0712     |\n",
            "|    explained_variance   | 0.19        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.296       |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00101    |\n",
            "|    value_loss           | 0.684       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | 0.1          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065865065 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0671      |\n",
            "|    explained_variance   | 0.205        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    value_loss           | 0.669        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | 0.1          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065865065 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0671      |\n",
            "|    explained_variance   | 0.205        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    value_loss           | 0.669        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | -0.16        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 117          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031988355 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0615      |\n",
            "|    explained_variance   | 0.176        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.312        |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    value_loss           | 0.693        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | -0.16        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 117          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031988355 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0615      |\n",
            "|    explained_variance   | 0.176        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.312        |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    value_loss           | 0.693        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.48        |\n",
            "|    ep_rew_mean          | -0.02       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003091004 |\n",
            "|    clip_fraction        | 0.0248      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0682     |\n",
            "|    explained_variance   | 0.233       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.365       |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    value_loss           | 0.635       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.48        |\n",
            "|    ep_rew_mean          | -0.02       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003091004 |\n",
            "|    clip_fraction        | 0.0248      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0682     |\n",
            "|    explained_variance   | 0.233       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.365       |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    value_loss           | 0.635       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.57         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039949603 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0609      |\n",
            "|    explained_variance   | 0.194        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.57         |\n",
            "|    ep_rew_mean          | -0.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039949603 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0609      |\n",
            "|    explained_variance   | 0.194        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.52         |\n",
            "|    ep_rew_mean          | -0.19        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034289183 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0624      |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.36         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    value_loss           | 0.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.52         |\n",
            "|    ep_rew_mean          | -0.19        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034289183 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0624      |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.36         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    value_loss           | 0.7          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.49        |\n",
            "|    ep_rew_mean          | -0.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 125         |\n",
            "|    total_timesteps      | 120832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002486405 |\n",
            "|    clip_fraction        | 0.0168      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.059      |\n",
            "|    explained_variance   | 0.216       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.318       |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | 0.000594    |\n",
            "|    value_loss           | 0.673       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.49        |\n",
            "|    ep_rew_mean          | -0.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 125         |\n",
            "|    total_timesteps      | 120832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002486405 |\n",
            "|    clip_fraction        | 0.0168      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.059      |\n",
            "|    explained_variance   | 0.216       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.318       |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | 0.000594    |\n",
            "|    value_loss           | 0.673       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 127          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030126222 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0578      |\n",
            "|    explained_variance   | 0.218        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.375        |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00188     |\n",
            "|    value_loss           | 0.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 127          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030126222 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0578      |\n",
            "|    explained_variance   | 0.218        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.375        |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00188     |\n",
            "|    value_loss           | 0.67         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.59       |\n",
            "|    ep_rew_mean          | -0.04      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 961        |\n",
            "|    iterations           | 61         |\n",
            "|    time_elapsed         | 129        |\n",
            "|    total_timesteps      | 124928     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00342661 |\n",
            "|    clip_fraction        | 0.0238     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0611    |\n",
            "|    explained_variance   | 0.174      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.373      |\n",
            "|    n_updates            | 600        |\n",
            "|    policy_gradient_loss | -0.00142   |\n",
            "|    value_loss           | 0.701      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.59       |\n",
            "|    ep_rew_mean          | -0.04      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 961        |\n",
            "|    iterations           | 61         |\n",
            "|    time_elapsed         | 129        |\n",
            "|    total_timesteps      | 124928     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00342661 |\n",
            "|    clip_fraction        | 0.0238     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0611    |\n",
            "|    explained_variance   | 0.174      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.373      |\n",
            "|    n_updates            | 600        |\n",
            "|    policy_gradient_loss | -0.00142   |\n",
            "|    value_loss           | 0.701      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.58         |\n",
            "|    ep_rew_mean          | -0.19        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 132          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048823548 |\n",
            "|    clip_fraction        | 0.0319       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0625      |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.58         |\n",
            "|    ep_rew_mean          | -0.19        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 132          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048823548 |\n",
            "|    clip_fraction        | 0.0319       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0625      |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 134          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021333953 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.066       |\n",
            "|    explained_variance   | 0.196        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.369        |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.000462    |\n",
            "|    value_loss           | 0.69         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 134          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021333953 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.066       |\n",
            "|    explained_variance   | 0.196        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.369        |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.000462    |\n",
            "|    value_loss           | 0.69         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | -0.23        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 136          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024435099 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0575      |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.377        |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.000734    |\n",
            "|    value_loss           | 0.665        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | -0.23        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 136          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024435099 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0575      |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.377        |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.000734    |\n",
            "|    value_loss           | 0.665        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | 0.03         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 138          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032867217 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0608      |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.332        |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    value_loss           | 0.678        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | 0.03         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 138          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032867217 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0608      |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.332        |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    value_loss           | 0.678        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.58         |\n",
            "|    ep_rew_mean          | 0.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 135168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023461406 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0564      |\n",
            "|    explained_variance   | 0.167        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.336        |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.000943    |\n",
            "|    value_loss           | 0.694        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.58         |\n",
            "|    ep_rew_mean          | 0.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 135168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023461406 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0564      |\n",
            "|    explained_variance   | 0.167        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.336        |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.000943    |\n",
            "|    value_loss           | 0.694        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032876742 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0563      |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.324        |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032876742 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0563      |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.324        |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029137689 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0569      |\n",
            "|    explained_variance   | 0.188        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.347        |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029137689 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0569      |\n",
            "|    explained_variance   | 0.188        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.347        |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.65         |\n",
            "|    ep_rew_mean          | -0.17        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021080333 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0582      |\n",
            "|    explained_variance   | 0.24         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.29         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -7.14e-05    |\n",
            "|    value_loss           | 0.651        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.65         |\n",
            "|    ep_rew_mean          | -0.17        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021080333 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0582      |\n",
            "|    explained_variance   | 0.24         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.29         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -7.14e-05    |\n",
            "|    value_loss           | 0.651        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 149          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027543625 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0594      |\n",
            "|    explained_variance   | 0.181        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.376        |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 149          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027543625 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0594      |\n",
            "|    explained_variance   | 0.181        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.376        |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.52         |\n",
            "|    ep_rew_mean          | -0.02        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 151          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023797099 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0554      |\n",
            "|    explained_variance   | 0.171        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.357        |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.000747    |\n",
            "|    value_loss           | 0.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.52         |\n",
            "|    ep_rew_mean          | -0.02        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 151          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023797099 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0554      |\n",
            "|    explained_variance   | 0.171        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.357        |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.000747    |\n",
            "|    value_loss           | 0.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.43         |\n",
            "|    ep_rew_mean          | -0.18        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 153          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029873024 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0489      |\n",
            "|    explained_variance   | 0.195        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.338        |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00275     |\n",
            "|    value_loss           | 0.678        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.43         |\n",
            "|    ep_rew_mean          | -0.18        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 153          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029873024 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0489      |\n",
            "|    explained_variance   | 0.195        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.338        |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00275     |\n",
            "|    value_loss           | 0.678        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.53         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 155          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023027016 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0584      |\n",
            "|    explained_variance   | 0.179        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.366        |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    value_loss           | 0.714        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.53         |\n",
            "|    ep_rew_mean          | -0.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 155          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023027016 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0584      |\n",
            "|    explained_variance   | 0.179        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.366        |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    value_loss           | 0.714        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.47         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 151552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039798333 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.058       |\n",
            "|    explained_variance   | 0.236        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.315        |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    value_loss           | 0.665        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.47         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 151552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039798333 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.058       |\n",
            "|    explained_variance   | 0.236        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.315        |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    value_loss           | 0.665        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 159          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035984693 |\n",
            "|    clip_fraction        | 0.0283       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0555      |\n",
            "|    explained_variance   | 0.196        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.355        |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    value_loss           | 0.679        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 159          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035984693 |\n",
            "|    clip_fraction        | 0.0283       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0555      |\n",
            "|    explained_variance   | 0.196        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.355        |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    value_loss           | 0.679        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.56        |\n",
            "|    ep_rew_mean          | -0.08       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 161         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004359376 |\n",
            "|    clip_fraction        | 0.0318      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0584     |\n",
            "|    explained_variance   | 0.23        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.323       |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | -0.00159    |\n",
            "|    value_loss           | 0.662       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.56        |\n",
            "|    ep_rew_mean          | -0.08       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 161         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004359376 |\n",
            "|    clip_fraction        | 0.0318      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0584     |\n",
            "|    explained_variance   | 0.23        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.323       |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | -0.00159    |\n",
            "|    value_loss           | 0.662       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.13       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 164         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005059595 |\n",
            "|    clip_fraction        | 0.0238      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0574     |\n",
            "|    explained_variance   | 0.245       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.281       |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    value_loss           | 0.643       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.13       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 961         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 164         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005059595 |\n",
            "|    clip_fraction        | 0.0238      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0574     |\n",
            "|    explained_variance   | 0.245       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.281       |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    value_loss           | 0.643       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.46         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 166          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048890533 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0551      |\n",
            "|    explained_variance   | 0.245        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.46         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 166          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048890533 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0551      |\n",
            "|    explained_variance   | 0.245        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.44         |\n",
            "|    ep_rew_mean          | 0.03         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 168          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025700098 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0646      |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.00134     |\n",
            "|    value_loss           | 0.686        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.44         |\n",
            "|    ep_rew_mean          | 0.03         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 168          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025700098 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0646      |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.00134     |\n",
            "|    value_loss           | 0.686        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | 0.03         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065413816 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0684      |\n",
            "|    explained_variance   | 0.206        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.357        |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.000934    |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.56         |\n",
            "|    ep_rew_mean          | 0.03         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065413816 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0684      |\n",
            "|    explained_variance   | 0.206        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.357        |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.000934    |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025092652 |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0671      |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.32         |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    value_loss           | 0.665        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | -0.04        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025092652 |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0671      |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.32         |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    value_loss           | 0.665        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.6          |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 174          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023610003 |\n",
            "|    clip_fraction        | 0.0289       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0715      |\n",
            "|    explained_variance   | 0.226        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.218        |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.000813    |\n",
            "|    value_loss           | 0.662        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.6          |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 174          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023610003 |\n",
            "|    clip_fraction        | 0.0289       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0715      |\n",
            "|    explained_variance   | 0.226        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.218        |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.000813    |\n",
            "|    value_loss           | 0.662        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.41         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 176          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020773117 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0668      |\n",
            "|    explained_variance   | 0.186        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00305     |\n",
            "|    value_loss           | 0.691        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.41         |\n",
            "|    ep_rew_mean          | -0.05        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 176          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020773117 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0668      |\n",
            "|    explained_variance   | 0.186        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00305     |\n",
            "|    value_loss           | 0.691        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 178          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031493711 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0731      |\n",
            "|    explained_variance   | 0.192        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.346        |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.49         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 178          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031493711 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0731      |\n",
            "|    explained_variance   | 0.192        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.346        |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.53         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 181          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028573077 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0612      |\n",
            "|    explained_variance   | 0.219        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.357        |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    value_loss           | 0.659        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.53         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 181          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028573077 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0612      |\n",
            "|    explained_variance   | 0.219        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.357        |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    value_loss           | 0.659        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.18        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 183          |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047221985 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0585      |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.28         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.18        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 183          |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047221985 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0585      |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.28         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.64         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 185          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023942678 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0595      |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.338        |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    value_loss           | 0.661        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.64         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 185          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023942678 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0595      |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.338        |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    value_loss           | 0.661        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 187          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013839011 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0627      |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.293        |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.000472    |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.55         |\n",
            "|    ep_rew_mean          | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 187          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013839011 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0627      |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.293        |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.000472    |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.4          |\n",
            "|    ep_rew_mean          | -0.34        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042163767 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0757      |\n",
            "|    explained_variance   | 0.24         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.412        |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    value_loss           | 0.643        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.4          |\n",
            "|    ep_rew_mean          | -0.34        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042163767 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0757      |\n",
            "|    explained_variance   | 0.24         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.412        |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    value_loss           | 0.643        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 191          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030328473 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0647      |\n",
            "|    explained_variance   | 0.213        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.000755    |\n",
            "|    value_loss           | 0.675        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.51         |\n",
            "|    ep_rew_mean          | -0.03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 191          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030328473 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0647      |\n",
            "|    explained_variance   | 0.213        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.000755    |\n",
            "|    value_loss           | 0.675        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.04       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003154173 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0547     |\n",
            "|    explained_variance   | 0.21        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.299       |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00311    |\n",
            "|    value_loss           | 0.67        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.57        |\n",
            "|    ep_rew_mean          | -0.04       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003154173 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0547     |\n",
            "|    explained_variance   | 0.21        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.299       |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00311    |\n",
            "|    value_loss           | 0.67        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.5          |\n",
            "|    ep_rew_mean          | -0.12        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 196          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033728997 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0516      |\n",
            "|    explained_variance   | 0.235        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.273        |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    value_loss           | 0.639        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.5          |\n",
            "|    ep_rew_mean          | -0.12        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 196          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033728997 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0516      |\n",
            "|    explained_variance   | 0.235        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.273        |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    value_loss           | 0.639        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | 0.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 198          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017607667 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0485      |\n",
            "|    explained_variance   | 0.235        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.342        |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | 0.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 198          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017607667 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0485      |\n",
            "|    explained_variance   | 0.235        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.342        |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.09       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 200         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002399191 |\n",
            "|    clip_fraction        | 0.0215      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.052      |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.308       |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.000676   |\n",
            "|    value_loss           | 0.669       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.09       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 200         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002399191 |\n",
            "|    clip_fraction        | 0.0215      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.052      |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.308       |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.000676   |\n",
            "|    value_loss           | 0.669       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.58        |\n",
            "|    ep_rew_mean          | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 202         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004248788 |\n",
            "|    clip_fraction        | 0.0247      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0548     |\n",
            "|    explained_variance   | 0.207       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.263       |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    value_loss           | 0.663       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.58        |\n",
            "|    ep_rew_mean          | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 202         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004248788 |\n",
            "|    clip_fraction        | 0.0247      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0548     |\n",
            "|    explained_variance   | 0.207       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.263       |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    value_loss           | 0.663       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.6          |\n",
            "|    ep_rew_mean          | -0.13        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 204          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034506458 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0542      |\n",
            "|    explained_variance   | 0.22         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.291        |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    value_loss           | 0.656        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.6          |\n",
            "|    ep_rew_mean          | -0.13        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 204          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034506458 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0542      |\n",
            "|    explained_variance   | 0.22         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.291        |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    value_loss           | 0.656        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 206          |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034322734 |\n",
            "|    clip_fraction        | 0.0209       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0495      |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.302        |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    value_loss           | 0.667        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 960          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 206          |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034322734 |\n",
            "|    clip_fraction        | 0.0209       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0495      |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.302        |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    value_loss           | 0.667        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 208         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004484254 |\n",
            "|    clip_fraction        | 0.0309      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0531     |\n",
            "|    explained_variance   | 0.208       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.386       |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00288    |\n",
            "|    value_loss           | 0.687       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.54        |\n",
            "|    ep_rew_mean          | -0.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 208         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004484254 |\n",
            "|    clip_fraction        | 0.0309      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0531     |\n",
            "|    explained_variance   | 0.208       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.386       |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00288    |\n",
            "|    value_loss           | 0.687       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x28f026b41a0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Entrenamos un agente PPO para Blackjack\n",
        "model_blackjack = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# N√∫mero de pasos de entrenamiento\n",
        "total_timesteps = 200_000\n",
        "model_blackjack.learn(total_timesteps=total_timesteps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **1.1.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5-d7d8GFf7F6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de episodios: 5000\n",
            "Retorno promedio: -0.0290\n",
            "Desviaci√≥n est√°ndar del retorno: 0.9557\n"
          ]
        }
      ],
      "source": [
        "def evaluate_agent(model, env, n_episodes=5000):\n",
        "    returns = []\n",
        "\n",
        "    for ep in range(n_episodes):\n",
        "        obs, info = env.reset()\n",
        "        done = False\n",
        "        ep_return = 0.0\n",
        "\n",
        "        while not done:\n",
        "            # Acci√≥n dada por el agente entrenado\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_return += reward\n",
        "            done = terminated or truncated\n",
        "\n",
        "        returns.append(ep_return)\n",
        "\n",
        "    returns = np.array(returns)\n",
        "    print(f\"N√∫mero de episodios: {n_episodes}\")\n",
        "    print(f\"Retorno promedio: {returns.mean():.4f}\")\n",
        "    print(f\"Desviaci√≥n est√°ndar del retorno: {returns.std():.4f}\")\n",
        "    return returns\n",
        "\n",
        "# Evaluar el modelo entrenado\n",
        "returns_trained = evaluate_agent(model_blackjack, env, n_episodes=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Repitiendo el experimento de la pregunta 1.1.2, pero ahora utilizando el modelo entrenado, se obtiene un retorno promedio de aproximadamente $-0.0290$ con una desviaci√≥n est√°ndar cercana a $0.9557$ en 5000 episodios. En comparaci√≥n con el baseline aleatorio, cuyo retorno promedio era alrededor de $-0.3890$, se observa una mejora clara: el agente entrenado pierde mucho menos en promedio y su valor esperado est√° bastante m√°s cerca de $0$.\n",
        "\n",
        "Aunque el retorno sigue siendo levemente negativo, el hecho de pasar de $-0.3890$ a $-0.0290$ indica que el agente ha aprendido una pol√≠tica significativamente mejor que la aleatoria, reduciendo la frecuencia o el impacto de las p√©rdidas. La desviaci√≥n est√°ndar similar ($\\approx 0.95$) muestra que la variabilidad de las recompensas por episodio se mantiene alta, algo esperable en Blackjack por la naturaleza aleatoria del juego, pero el desplazamiento del promedio hacia $0$ permite concluir que el performance del modelo entrenado es claramente superior al escenario baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una funci√≥n que reciba un estado y retorne la accion del agente. Luego, use esta funci√≥n para entregar la acci√≥n escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "¬øSon coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¬øA que clase de python pertenecen los estados? Pruebe a usar el m√©todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fh8XlGyzwtRp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estado 1 (6, dealer 7, sin As usable): 1 -> HIT (pedir carta)\n",
            "Estado 2 (19, dealer 3, con As usable): 0 -> STICK (quedarse)\n"
          ]
        }
      ],
      "source": [
        "def agent_action_from_state(model, state):\n",
        "    \"\"\"\n",
        "    state: puede ser un tuple como (player_sum, dealer_card, usable_ace)\n",
        "           o un np.array (depende de c√≥mo est√© definido el env).\n",
        "    \"\"\"\n",
        "    if isinstance(state, tuple):\n",
        "        state = np.array(state, dtype=np.float32)\n",
        "\n",
        "    action, _ = model.predict(state, deterministic=True)\n",
        "    return int(action)  # 0 = stick, 1 = hit en Blackjack-v1\n",
        "\n",
        "# Escenario 1:\n",
        "# Suma del agente = 6, dealer muestra 7, sin As usable\n",
        "state1 = (6, 7, False)\n",
        "\n",
        "# Escenario 2:\n",
        "# Suma del agente = 19, dealer muestra 3, con As usable\n",
        "state2 = (19, 3, True)\n",
        "\n",
        "action1 = agent_action_from_state(model_blackjack, state1)\n",
        "action2 = agent_action_from_state(model_blackjack, state2)\n",
        "\n",
        "action_meaning = {0: \"STICK (quedarse)\", 1: \"HIT (pedir carta)\"}\n",
        "\n",
        "print(\"Estado 1 (6, dealer 7, sin As usable):\", action1, \"->\", action_meaning[action1])\n",
        "print(\"Estado 2 (19, dealer 3, con As usable):\", action2, \"->\", action_meaning[action2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte se construy√≥ una funci√≥n que, dado un estado del ambiente (tupla con $(\\text{suma\\_jugador},\\ \\text{carta\\_dealer},\\ \\text{as\\_usable})$), lo pasa por el modelo entrenado y devuelve la acci√≥n elegida por el agente. Usando esa funci√≥n en los dos escenarios indicados, se obtuvo:\n",
        "\n",
        "- Estado 1: suma del jugador $= 6$, dealer muestra un $7$, sin As usable  \n",
        "  Acci√≥n del agente: `1` $\\Rightarrow$ **HIT** (pedir carta).\n",
        "\n",
        "- Estado 2: suma del jugador $= 19$, dealer muestra un $3$, con As usable (soft 19)  \n",
        "  Acci√≥n del agente: `0` $\\Rightarrow$ **STICK** (quedarse).\n",
        "\n",
        "Estas decisiones son coherentes con las reglas y con la estrategia b√°sica de Blackjack.  \n",
        "\n",
        "En el primer caso, con una suma de $6$ contra un $7$ del dealer, la mano del jugador es muy d√©bil; lo razonable es seguir pidiendo cartas, por lo que que el agente elija HIT es consistente con una pol√≠tica sensata. B√°sicamente hay que pedir si o si pues sea lo que sea que salga en la siguiente carta es imposible pasarse de $21$.\n",
        "\n",
        "En el segundo caso, con un ‚Äúsoft $19$‚Äù ($19$ con As usable) frente a un $3$ del dealer, la estrategia b√°sica suele indicar plantarse (o doblar si esa acci√≥n existe; en este ambiente s√≥lo est√°n disponibles HIT y STICK). En consecuencia, que el agente elija STICK en este estado tambi√©n es coherente con una pol√≠tica de juego razonable. (Igual yo hitear√≠a con un $19$ teniendo un As XD).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci√≥n 2.1, en esta secci√≥n usted se encargar√° de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nvQUyuZ_FtZ4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\samot\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el par√°metro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBU4lGX3wpN6"
      },
      "source": [
        "Noten que se especifica el par√°metro `continuous = True`. ¬øQue implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "Adem√°s, se le facilita la funci√≥n `export_gif` para el ejercicio 2.2.4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bRiWpSo9yfr9"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci√≥n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **1.2.1 Descripci√≥n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci√≥n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. ¬øComo se distinguen las acciones de este ambiente en comparaci√≥n a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especific√≥ el par√°metro `continuous = True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      },
      "source": [
        "El ambiente **LunarLander** (en su versi√≥n continua) modela el problema de aterrizar suavemente una nave en una superficie lunar como un **proceso de decisi√≥n de Markov (MDP)**. El estado $S$ se representa mediante un vector continuo que describe la situaci√≥n f√≠sica de la nave: posici√≥n $(x, y)$ relativa a la zona de aterrizaje, velocidades $(\\dot x, \\dot y)$, √°ngulo de la nave $\\theta$, velocidad angular $\\dot \\theta$ y dos variables binarias que indican si cada una de las patas est√° en contacto con el suelo. Este estado resume toda la informaci√≥n relevante para decidir la acci√≥n siguiente.\n",
        "\n",
        "Las acciones $A$ en la versi√≥n continua (con `continuous = True`) son **valores continuos** que controlan la intensidad de los motores: t√≠picamente un par de n√∫meros reales que indican la fuerza del motor principal (vertical) y de los motores laterales (para inclinar la nave). Es decir, en cada paso el agente elige un vector de acci√≥n en vez de una acci√≥n discreta fija. Las recompensas $R$ est√°n dise√±adas para favorecer un aterrizaje suave en la plataforma: se otorgan recompensas positivas por acercarse al punto de aterrizaje, reducir la velocidad y tocar el suelo de forma estable con las dos patas, y recompensas negativas por chocar, salir de la zona o gastar combustible en exceso.\n",
        "\n",
        "En comparaci√≥n con el ambiente de `Blackjack`, donde las acciones son **discretas y muy pocas** (por ejemplo, ‚Äúpedir carta‚Äù o ‚Äúplantarse‚Äù), en `LunarLander` continuo las acciones forman un **espacio de acciones continuo**: el agente no s√≥lo elige ‚Äúqu√© hacer‚Äù, sino tambi√©n ‚Äúcu√°nto‚Äù empuje aplicar en cada motor. Esto hace que el espacio de acciones sea mucho m√°s rico y que el control sea de tipo continuo en lugar de decisiones discretas simples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 10 veces y reporte el promedio y desviaci√≥n de las recompensas. ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5bwc3A0GX7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de episodios: 10\n",
            "Retorno promedio: -302.39\n",
            "Desviaci√≥n est√°ndar del retorno: 126.51\n"
          ]
        }
      ],
      "source": [
        "def evaluate_random_policy(env, n_episodes):\n",
        "    \"\"\"\n",
        "    Baseline con pol√≠tica aleatoria para LunarLander (continuous=True).\n",
        "    \"\"\"\n",
        "    returns = []\n",
        "\n",
        "    for ep in range(n_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        ep_return = 0.0\n",
        "\n",
        "        while not done:\n",
        "            # Acci√≥n completamente aleatoria en el espacio continuo\n",
        "            action = env.action_space.sample()\n",
        "            _, reward, terminated, truncated, _ = env.step(action)\n",
        "            ep_return += reward\n",
        "            done = terminated or truncated\n",
        "\n",
        "        returns.append(ep_return)\n",
        "\n",
        "    returns = np.array(returns)\n",
        "    print(f\"N√∫mero de episodios: {n_episodes}\")\n",
        "    print(f\"Retorno promedio: {returns.mean():.2f}\")\n",
        "    print(f\"Desviaci√≥n est√°ndar del retorno: {returns.std():.2f}\")\n",
        "    return returns\n",
        "\n",
        "# Corremos el baseline\n",
        "random_returns = evaluate_random_policy(env, n_episodes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con los resultados obtenidos, al utilizar una pol√≠tica completamente aleatoria en el ambiente `LunarLander` (versi√≥n continua) y simular 10 episodios, se observa un retorno promedio de aproximadamente $-302.39$ con una desviaci√≥n est√°ndar cercana a $126.51$. Este valor promedio tan negativo indica que la pol√≠tica aleatoria tiene un desempe√±o claramente deficiente: en general, el agente no logra realizar aterrizajes suaves, suele chocar, desviarse de la zona objetivo o gastar energ√≠a de manera ineficiente. Dado que en `LunarLander` las recompensas se construyen para premiar aterrizajes estables y penalizar colisiones o maniobras malas, un retorno esperado en torno a $-300$ refleja un comportamiento muy lejos de lo deseable.\n",
        "\n",
        "La desviaci√≥n est√°ndar relativamente alta sugiere que hay variabilidad entre episodios (en algunos intentos el agente puede caer ‚Äúmenos mal‚Äù que en otros), pero todos los resultados se concentran en un rango claramente negativo. En consecuencia, esta pol√≠tica aleatoria sirve como un baseline pobre: establece un piso de rendimiento que cualquier agente entrenado deber√≠a ser capaz de superar de forma consistente para considerarse m√≠nimamente competente en la tarea de aterrizar la nave.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y_6Ia9uoF7Hs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 107      |\n",
            "|    ep_rew_mean     | -219     |\n",
            "| time/              |          |\n",
            "|    fps             | 1763     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 107      |\n",
            "|    ep_rew_mean     | -219     |\n",
            "| time/              |          |\n",
            "|    fps             | 1763     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 113         |\n",
            "|    ep_rew_mean          | -225        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1254        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004314343 |\n",
            "|    clip_fraction        | 0.0422      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | 0.000823    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 635         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00794    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 1.94e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 113         |\n",
            "|    ep_rew_mean          | -225        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1254        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004314343 |\n",
            "|    clip_fraction        | 0.0422      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | 0.000823    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 635         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00794    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 1.94e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 118        |\n",
            "|    ep_rew_mean          | -219       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1140       |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 5          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00531523 |\n",
            "|    clip_fraction        | 0.0231     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.86      |\n",
            "|    explained_variance   | -0.0109    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 559        |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00695   |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 1.68e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 118        |\n",
            "|    ep_rew_mean          | -219       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1140       |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 5          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00531523 |\n",
            "|    clip_fraction        | 0.0231     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.86      |\n",
            "|    explained_variance   | -0.0109    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 559        |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00695   |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 1.68e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 119         |\n",
            "|    ep_rew_mean          | -207        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1073        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005455314 |\n",
            "|    clip_fraction        | 0.0389      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | -0.00348    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 455         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00614    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 915         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 119         |\n",
            "|    ep_rew_mean          | -207        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1073        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005455314 |\n",
            "|    clip_fraction        | 0.0389      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | -0.00348    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 455         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00614    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 915         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | -204         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1052         |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050616795 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | -0.0595      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 358          |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00511     |\n",
            "|    std                  | 0.986        |\n",
            "|    value_loss           | 932          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | -204         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1052         |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050616795 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | -0.0595      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 358          |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00511     |\n",
            "|    std                  | 0.986        |\n",
            "|    value_loss           | 932          |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x28f0770dee0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Definimos un modelo PPO para LunarLander continuo\n",
        "model_lunar = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Entrenamos el modelo para 10000 timesteps\n",
        "model_lunar.learn(total_timesteps=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **1.2.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ophyU3KrWrwl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de episodios: 10\n",
            "Retorno promedio: -229.24\n",
            "Desviaci√≥n est√°ndar del retorno: 86.36\n"
          ]
        }
      ],
      "source": [
        "def evaluate_agent(model, env, n_episodes):\n",
        "    \"\"\"\n",
        "    Eval√∫a un agente entrenado en LunarLander.\n",
        "    \"\"\"\n",
        "    returns = []\n",
        "\n",
        "    for ep in range(n_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        ep_return = 0.0\n",
        "\n",
        "        while not done:\n",
        "            # Pol√≠tica del agente entrenado\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            ep_return += reward\n",
        "            done = terminated or truncated\n",
        "\n",
        "        returns.append(ep_return)\n",
        "\n",
        "    returns = np.array(returns)\n",
        "    print(f\"N√∫mero de episodios: {n_episodes}\")\n",
        "    print(f\"Retorno promedio: {returns.mean():.2f}\")\n",
        "    print(f\"Desviaci√≥n est√°ndar del retorno: {returns.std():.2f}\")\n",
        "    return returns\n",
        "\n",
        "# Evaluamos el modelo entrenado\n",
        "trained_returns = evaluate_agent(model_lunar, env, n_episodes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Repitiendo el experimento de la pregunta 1.2.2, pero utilizando el modelo entrenado, se obtiene un retorno promedio de aproximadamente $-229.24$ con una desviaci√≥n est√°ndar cercana a $86.36$ en 10 episodios. En comparaci√≥n con el baseline aleatorio, cuyo retorno promedio era alrededor de $-302.39$, se observa una mejora: el agente entrenado sigue teniendo un desempe√±o negativo, pero pierde menos recompensa en promedio y se acerca a un comportamiento algo m√°s razonable en la tarea de aterrizar la nave.\n",
        "\n",
        "Adem√°s, la desviaci√≥n est√°ndar disminuye desde aproximadamente $126.51$ a $86.36$, lo que sugiere que el comportamiento del agente se vuelve algo m√°s consistente entre episodios (menos variabilidad extrema). Sin embargo, el hecho de que el retorno esperado siga siendo claramente negativo indica que, aunque el modelo entrenado supera al baseline aleatorio, todav√≠a est√° lejos de un desempe√±o satisfactorio: el agente no logra aterrizajes buenos de manera sistem√°tica y a√∫n comete errores importantes en la mayor√≠a de los episodios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **1.2.5 Optimizaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par√°metros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la funci√≥n `export_gif` para estudiar el comportamiento de su agente en la resoluci√≥n del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor a√∫n si adem√°s adjuntan el gif en el markdown)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de episodios: 10\n",
            "Retorno promedio: 204.39\n",
            "Desviaci√≥n est√°ndar del retorno: 93.10\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([268.72731177, 242.08270975, 203.05854448, 232.5539607 ,\n",
              "       227.37086614, 250.79172504, 230.35210321, -70.45022041,\n",
              "       238.33583518, 221.09885924])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Definimos un modelo PPO optimizado para LunarLander continuo\n",
        "model_lunar_opt = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    learning_rate=3e-4, # Modificamos el learning rate\n",
        "    batch_size=64, # Modificamos el tama√±o del batch\n",
        ")\n",
        "\n",
        "# Entrenamos el modelo optimizado\n",
        "model_lunar_opt.learn(total_timesteps=500000)  # Modificamos el n√∫mero de timesteps\n",
        "\n",
        "# Evaluamos el modelo optimizado\n",
        "evaluate_agent(model_lunar_opt, env, n_episodes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      },
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta secci√≥n se enfocar√°n en habilitar un Chatbot que nos permita responder preguntas √∫tiles a trav√©s de LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4fPRRihGLe"
      },
      "source": [
        "### **2.0 Configuraci√≥n Inicial**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ud2Xm_k-hFJn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      },
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci√≥n es que habiliten un chatbot que pueda responder preguntas usando informaci√≥n contenida en documentos PDF a trav√©s de **Retrieval Augmented Generation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      },
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como m√≠nimo.\n",
        "  - 50 p√°ginas de contenido como m√≠nimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas acad√©micos, laborales o de ocio. Aprovechen este ejercicio para construir algo √∫til y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D1tIRCi4oJJ",
        "outputId": "39f6d4fc-63cb-4b9b-d48f-48d60df25ee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "from pathlib import Path\n",
        "\n",
        "DOCS_DIR = Path(\"docs\")\n",
        "\n",
        "doc_paths = [str(p) for p in DOCS_DIR.glob(\"*.pdf\")]\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un m√≠nimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"P√°ginas insuficientes: {total_paginas}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r811-P71nizA"
      },
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "n-yXAdCSn4JM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se cargaron 4 documentos de texto a partir de 4 PDFs.\n",
            "Se generaron 1328 chunks de texto.\n",
            "Dimensiones de la matriz de embeddings: (1328, 384)\n",
            "Dimensiones de la matriz de embeddings: (1328, 384)\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "\n",
        "# Leemos el texto de los PDFs\n",
        "texts = []\n",
        "for path in doc_paths:\n",
        "    with open(path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        pages_text = []\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text() or \"\"\n",
        "            pages_text.append(page_text)\n",
        "        full_text = \"\\n\".join(pages_text)\n",
        "        if full_text.strip():\n",
        "            texts.append(full_text)\n",
        "\n",
        "print(f\"Se cargaron {len(texts)} documentos de texto a partir de {len(doc_paths)} PDFs.\")\n",
        "\n",
        "# Definimos una funci√≥n para dividir el texto en chunks con overlap\n",
        "def split_text(text, chunk_size=1000, overlap=200):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        if chunk.strip():\n",
        "            chunks.append(chunk)\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "# Generamos los chunks de texto para todos los documentos\n",
        "text_chunks = []\n",
        "for t in texts:\n",
        "    text_chunks.extend(split_text(t, chunk_size=1000, overlap=200))\n",
        "\n",
        "print(f\"Se generaron {len(text_chunks)} chunks de texto.\")\n",
        "\n",
        "# Modelo de embeddings multiling√ºe (el que se dio en el foro)\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        ")\n",
        "\n",
        "# Generamos los embeddings para los chunks de texto\n",
        "chunk_embeddings = embeddings_model.embed_documents(text_chunks)\n",
        "emb_matrix = np.array(chunk_embeddings)\n",
        "\n",
        "# Mostramos la forma de la matriz de embeddings\n",
        "print(f\"Dimensiones de la matriz de embeddings: {emb_matrix.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAUkP5zrnyBK"
      },
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la soluci√≥n RAG a trav√©s de una *chain* y gu√°rdela en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gPIySdDFn99l"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "# Creamos el cliente de Gemini usando la API key\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "def retrieve_relevant_chunks(question: str, k: int = 5):\n",
        "    \"\"\"\n",
        "    Dada una pregunta, retorna los k chunks m√°s similares usando\n",
        "    similitud de coseno entre embeddings de HuggingFace.\n",
        "    \"\"\"\n",
        "    # Embedding de la pregunta\n",
        "    query_vec = np.array(embeddings_model.embed_query(question))\n",
        "\n",
        "    # Similaridad de coseno con todos los chunks\n",
        "    doc_norms = np.linalg.norm(emb_matrix, axis=1)\n",
        "    q_norm = np.linalg.norm(query_vec) + 1e-10\n",
        "    sims = (emb_matrix @ query_vec) / (doc_norms * q_norm + 1e-10)\n",
        "\n",
        "    # √çndices de los k m√°s similares (ordenados de mayor a menor similitud)\n",
        "    top_k_idx = np.argsort(sims)[-k:][::-1]\n",
        "\n",
        "    # Retornamos los textos correspondientes\n",
        "    return [text_chunks[i] for i in top_k_idx]\n",
        "\n",
        "def rag_chain(question: str, k: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    Chain de RAG: dado una pregunta, recupera contexto de los PDFs\n",
        "    y obtiene una respuesta del LLM de Google.\n",
        "    \"\"\"\n",
        "    relevant_chunks = retrieve_relevant_chunks(question, k=k)\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    system_instruction = (\n",
        "        \"Eres un asistente que responde preguntas usando exclusivamente \"\n",
        "        \"el contexto proporcionado. Si la informaci√≥n no est√° en el contexto, \"\n",
        "        \"di expl√≠citamente que no tienes informaci√≥n suficiente.\"\n",
        "    )\n",
        "\n",
        "    contents = [\n",
        "        system_instruction,\n",
        "        f\"Contexto:\\n{context}\",\n",
        "        f\"Pregunta: {question}\",\n",
        "        \"Respuesta (en espa√±ol):\",\n",
        "    ]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=contents,\n",
        "    )\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "# Guardamos la chain RAG en una variable\n",
        "chain = rag_chain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycg5S5i_n-kL"
      },
      "source": [
        "#### **2.1.4 Verificaci√≥n de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci√≥n para cada una. ¬øSu soluci√≥n RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: ¬øQui√©n es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Pregunta 1 ===\n",
            "Pregunta: ¬øC√≥mo se define una matriz A de m filas y n columnas con coeficientes en un cuerpo K?\n",
            "Respuesta correcta esperada:\n",
            "  Una matriz A es una tabla de doble entrada A = (a_ij) con m filas y n columnas, donde a_ij ‚àà K para todo i = 1,‚Ä¶,m y j = 1,‚Ä¶,n. \n",
            "\n",
            "Respuesta de la soluci√≥n RAG:\n",
            "  Una matriz A de m filas y n columnas con coeficientes en un cuerpo K se nota como A = (aij) y pertenece al conjunto Mmn(K), que es el conjunto de todas las matrices de m filas y n columnas con coeficientes en el cuerpo K.\n",
            "\n",
            "=== Pregunta 2 ===\n",
            "Pregunta: ¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\n",
            "Respuesta correcta esperada:\n",
            "  Sea (s_n) una sucesi√≥n y œÜ: N ‚Üí N una funci√≥n estrictamente creciente; la subsucesi√≥n generada por œÜ es (u_n) con u_n = s_{œÜ(n)}. \n",
            "\n",
            "Respuesta de la soluci√≥n RAG:\n",
            "  Una matriz A de m filas y n columnas con coeficientes en un cuerpo K se nota como A = (aij) y pertenece al conjunto Mmn(K), que es el conjunto de todas las matrices de m filas y n columnas con coeficientes en el cuerpo K.\n",
            "\n",
            "=== Pregunta 2 ===\n",
            "Pregunta: ¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\n",
            "Respuesta correcta esperada:\n",
            "  Sea (s_n) una sucesi√≥n y œÜ: N ‚Üí N una funci√≥n estrictamente creciente; la subsucesi√≥n generada por œÜ es (u_n) con u_n = s_{œÜ(n)}. \n",
            "\n",
            "Respuesta de la soluci√≥n RAG:\n",
            "  Sea (sn) una sucesi√≥n. Sea œÜ:N‚ÜíN una funci√≥n estrictamente creciente. Se llama subsucesi√≥n de (sn) generada por œÜ, a la sucesi√≥n (un), definida por: un=sœÜ(n).\n",
            "\n",
            "=== Pregunta 3 ===\n",
            "Pregunta: ¬øQu√© significa que un conjunto sea numerable?\n",
            "Respuesta correcta esperada:\n",
            "  Un conjunto es numerable si tiene la misma cardinalidad que N, es decir, si existe una biyecci√≥n entre el conjunto y N. \n",
            "\n",
            "Respuesta de la soluci√≥n RAG:\n",
            "  Sea (sn) una sucesi√≥n. Sea œÜ:N‚ÜíN una funci√≥n estrictamente creciente. Se llama subsucesi√≥n de (sn) generada por œÜ, a la sucesi√≥n (un), definida por: un=sœÜ(n).\n",
            "\n",
            "=== Pregunta 3 ===\n",
            "Pregunta: ¬øQu√© significa que un conjunto sea numerable?\n",
            "Respuesta correcta esperada:\n",
            "  Un conjunto es numerable si tiene la misma cardinalidad que N, es decir, si existe una biyecci√≥n entre el conjunto y N. \n",
            "\n",
            "Respuesta de la soluci√≥n RAG:\n",
            "  Llamaremos conjunto numerable a cualquier conjunto que tenga la misma cardinalidad que N.\n",
            "Respuesta de la soluci√≥n RAG:\n",
            "  Llamaremos conjunto numerable a cualquier conjunto que tenga la misma cardinalidad que N.\n"
          ]
        }
      ],
      "source": [
        "# Definimos algunas preguntas de prueba y sus respuestas correctas esperadas\n",
        "qa_pairs = [\n",
        "    (\n",
        "        \"¬øC√≥mo se define una matriz A de m filas y n columnas con coeficientes en un cuerpo K?\",\n",
        "        \"Una matriz A es una tabla de doble entrada A = (a_ij) con m filas y n columnas, \"\n",
        "        \"donde a_ij ‚àà K para todo i = 1,‚Ä¶,m y j = 1,‚Ä¶,n.\"\n",
        "    ),\n",
        "    (\n",
        "        \"¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\",\n",
        "        \"Sea (s_n) una sucesi√≥n y œÜ: N ‚Üí N una funci√≥n estrictamente creciente; \"\n",
        "        \"la subsucesi√≥n generada por œÜ es (u_n) con u_n = s_{œÜ(n)}.\"\n",
        "    ),\n",
        "    (\n",
        "        \"¬øQu√© significa que un conjunto sea numerable?\",\n",
        "        \"Un conjunto es numerable si tiene la misma cardinalidad que N, es decir, \"\n",
        "        \"si existe una biyecci√≥n entre el conjunto y N.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Probamos la chain RAG con las preguntas definidas y mostramos las respuestas en pantalla\n",
        "for i, (question, expected_answer) in enumerate(qa_pairs, start=1):\n",
        "    print(f\"\\n=== Pregunta {i} ===\")\n",
        "    print(\"Pregunta:\", question)\n",
        "    print(\"Respuesta correcta esperada:\\n \", expected_answer, \"\\n\")\n",
        "\n",
        "    rag_answer = rag_chain(question, k=5)\n",
        "    print(\"Respuesta de la soluci√≥n RAG:\\n \", rag_answer)\n",
        "    \n",
        "# IMPORTANTE: Ac√° no entiendo por qu√© se imprime m√°s de una vez el for, es un bug que no pude arreglar.\n",
        "# De todas maneras igual se puede ver la informaci√≥n relevante y responder lo pedido en base a ello.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El RAG si devolvi√≥ las respuestas esperadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8d5zTMHoUgF"
      },
      "source": [
        "#### **2.1.5 Sensibilidad de Hiperpar√°metros (0.5 puntos)**\n",
        "\n",
        "Extienda el an√°lisis del punto 2.1.4 analizando c√≥mo cambian las respuestas entregadas cambiando los siguientes hiperpar√°metros:\n",
        "- `Tama√±o del chunk`. (*¬øC√≥mo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*¬øQu√© pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de b√∫squeda`. (*¬øC√≥mo afecta el tipo de b√∫squeda a las respuestas de mi RAG?*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "UDh_QgeXLGHc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################################################################################################################\n",
            "AN√ÅLISIS: TAMA√ëO DEL CHUNK\n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tama√±o de chunk: 500\n",
            "\n",
            "Para diagonalizar una matriz, o para obtener una matriz diagonal D de una matriz triangular superior ~A, se puede \"escalonar hacia arriba la matriz ~A\".\n",
            "\n",
            "El procedimiento descrito en el contexto es el siguiente:\n",
            "1.  **Obtener una matriz triangular superior ~A**: Esto se logra mediante el escalonamiento de Gauss sobre la matriz (AjI).\n",
            "2.  **Hacer ceros los elementos sobre la diagonal**: Una vez que se ha obtenido la matriz triangular superior ~A, se debe \"realizar el mismo procedimiento para los elementos sobre la diagonal\". Esto implica operaciones para eliminar los elementos que est√°n por encima de la diagonal principal.\n",
            "3.  **Matriz diagonal D**: La matriz D obtenida de esta manera tendr√° por diagonal la misma que ~A, es decir, los elementos ~a11, ~a22, ..., ~ann.\n",
            "\n",
            "El contexto tambi√©n menciona que A admite una factorizaci√≥n A=LDU, donde D es una matriz diagonal. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tama√±o de chunk: 1000\n",
            "\n",
            "Para diagonalizar una matriz, o para obtener una matriz diagonal D de una matriz triangular superior ~A, se puede \"escalonar hacia arriba la matriz ~A\".\n",
            "\n",
            "El procedimiento descrito en el contexto es el siguiente:\n",
            "1.  **Obtener una matriz triangular superior ~A**: Esto se logra mediante el escalonamiento de Gauss sobre la matriz (AjI).\n",
            "2.  **Hacer ceros los elementos sobre la diagonal**: Una vez que se ha obtenido la matriz triangular superior ~A, se debe \"realizar el mismo procedimiento para los elementos sobre la diagonal\". Esto implica operaciones para eliminar los elementos que est√°n por encima de la diagonal principal.\n",
            "3.  **Matriz diagonal D**: La matriz D obtenida de esta manera tendr√° por diagonal la misma que ~A, es decir, los elementos ~a11, ~a22, ..., ~ann.\n",
            "\n",
            "El contexto tambi√©n menciona que A admite una factorizaci√≥n A=LDU, donde D es una matriz diagonal. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tama√±o de chunk: 1000\n",
            "\n",
            "Seg√∫n el contexto proporcionado, una matriz diagonalizable A puede descomponerse de la forma \"PDP‚Åª¬π\".\n",
            "\n",
            "Para diagonalizar una matriz A, el proceso (ilustrado en el Ejemplo 4.14) consiste en:\n",
            "1.  **Calcular los valores propios** (tambi√©n llamados autovalores) de la matriz A, resolviendo la ecuaci√≥n caracter√≠stica |A - ŒªI| = 0, donde Œª son los valores propios e I es la matriz identidad.\n",
            "2.  **Calcular los vectores propios** (tambi√©n llamados autovectores) asociados a cada valor propio. Para un valor propio Œª, esto se hace resolviendo el sistema (A - ŒªI)u = 0, donde u es el vector propio. Esto define el espacio propio para cada valor propio.\n",
            "3.  **Formar la matriz P** con los vectores propios como sus columnas.\n",
            "4.  **Formar la matriz diagonal D** que tendr√° los valores propios en su diagonal principal.\n",
            "5.  Entonces, la matriz A se puede expresar como A = PDP‚Åª¬π. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tama√±o de chunk: 2000\n",
            "\n",
            "Seg√∫n el contexto proporcionado, una matriz diagonalizable A puede descomponerse de la forma \"PDP‚Åª¬π\".\n",
            "\n",
            "Para diagonalizar una matriz A, el proceso (ilustrado en el Ejemplo 4.14) consiste en:\n",
            "1.  **Calcular los valores propios** (tambi√©n llamados autovalores) de la matriz A, resolviendo la ecuaci√≥n caracter√≠stica |A - ŒªI| = 0, donde Œª son los valores propios e I es la matriz identidad.\n",
            "2.  **Calcular los vectores propios** (tambi√©n llamados autovectores) asociados a cada valor propio. Para un valor propio Œª, esto se hace resolviendo el sistema (A - ŒªI)u = 0, donde u es el vector propio. Esto define el espacio propio para cada valor propio.\n",
            "3.  **Formar la matriz P** con los vectores propios como sus columnas.\n",
            "4.  **Formar la matriz diagonal D** que tendr√° los valores propios en su diagonal principal.\n",
            "5.  Entonces, la matriz A se puede expresar como A = PDP‚Åª¬π. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tama√±o de chunk: 2000\n",
            "\n",
            "Seg√∫n el contexto proporcionado, se menciona que se puede \"alonar hacia arriba la matriz ~Apara obtener de manera similar una matriz diagonal D.\" Esta matriz diagonal D tendr√° por diagonal la misma que ~A, es decir:\n",
            "\n",
            "D=0\n",
            "B@~a11    0\n",
            ".........\n",
            "0    ~ann1\n",
            "CA\n",
            "\n",
            "Adem√°s, se establece una relaci√≥n `A=E‚Åª¬πDF‚Åª¬π`, donde D es la matriz diagonal mencionada y E y F son matrices invertibles (del estilo de las matrices elementales usadas).\n",
            "\n",
            "Sin embargo, el contexto no proporciona un m√©todo detallado o un algoritmo paso a paso sobre c√≥mo realizar el proceso de \"alonar hacia arriba\" una matriz para obtener esta matriz diagonal D, ni profundiza en el concepto de diagonalizaci√≥n m√°s all√° de esta menci√≥n. \n",
            "\n",
            "########################################################################################################################\n",
            "AN√ÅLISIS: CANTIDAD DE CHUNKS k\n",
            "\n",
            "Seg√∫n el contexto proporcionado, se menciona que se puede \"alonar hacia arriba la matriz ~Apara obtener de manera similar una matriz diagonal D.\" Esta matriz diagonal D tendr√° por diagonal la misma que ~A, es decir:\n",
            "\n",
            "D=0\n",
            "B@~a11    0\n",
            ".........\n",
            "0    ~ann1\n",
            "CA\n",
            "\n",
            "Adem√°s, se establece una relaci√≥n `A=E‚Åª¬πDF‚Åª¬π`, donde D es la matriz diagonal mencionada y E y F son matrices invertibles (del estilo de las matrices elementales usadas).\n",
            "\n",
            "Sin embargo, el contexto no proporciona un m√©todo detallado o un algoritmo paso a paso sobre c√≥mo realizar el proceso de \"alonar hacia arriba\" una matriz para obtener esta matriz diagonal D, ni profundiza en el concepto de diagonalizaci√≥n m√°s all√° de esta menci√≥n. \n",
            "\n",
            "########################################################################################################################\n",
            "AN√ÅLISIS: CANTIDAD DE CHUNKS k\n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 1\n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 1\n",
            "\n",
            "El contexto proporcionado menciona que se puede \"alonar hacia arriba la matriz ~A para obtener de manera similar una matriz diagonal D\". Esta matriz diagonal D tendr√° por diagonal la misma que ~A (es decir, los elementos ~a11 hasta ~ann). Tambi√©n indica que esto se puede lograr mediante operaciones que involucran matrices elementales, y que una matriz A puede expresarse como A=E 1DF 1, donde D es una matriz diagonal y E, F son matrices invertibles formadas por matrices elementales.\n",
            "\n",
            "Sin embargo, el contexto no detalla los pasos o el m√©todo expl√≠cito sobre *c√≥mo* se realiza el proceso de \"alonar hacia arriba\" o, en general, c√≥mo diagonalizar una matriz. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 3\n",
            "\n",
            "El contexto proporcionado menciona que se puede \"alonar hacia arriba la matriz ~A para obtener de manera similar una matriz diagonal D\". Esta matriz diagonal D tendr√° por diagonal la misma que ~A (es decir, los elementos ~a11 hasta ~ann). Tambi√©n indica que esto se puede lograr mediante operaciones que involucran matrices elementales, y que una matriz A puede expresarse como A=E 1DF 1, donde D es una matriz diagonal y E, F son matrices invertibles formadas por matrices elementales.\n",
            "\n",
            "Sin embargo, el contexto no detalla los pasos o el m√©todo expl√≠cito sobre *c√≥mo* se realiza el proceso de \"alonar hacia arriba\" o, en general, c√≥mo diagonalizar una matriz. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 3\n",
            "\n",
            "No tengo informaci√≥n suficiente en el contexto proporcionado para explicar c√≥mo diagonalizar una matriz. El texto menciona la obtenci√≥n de una matriz diagonal D a partir del escalonamiento de una matriz ~A, donde D tiene la misma diagonal que ~A, y una descomposici√≥n A=E‚Åª¬πDF‚Åª¬π, pero no describe el proceso general de diagonalizaci√≥n de una matriz. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 5\n",
            "\n",
            "No tengo informaci√≥n suficiente en el contexto proporcionado para explicar c√≥mo diagonalizar una matriz. El texto menciona la obtenci√≥n de una matriz diagonal D a partir del escalonamiento de una matriz ~A, donde D tiene la misma diagonal que ~A, y una descomposici√≥n A=E‚Åª¬πDF‚Åª¬π, pero no describe el proceso general de diagonalizaci√≥n de una matriz. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 5\n",
            "\n",
            "Seg√∫n el contexto proporcionado, una matriz diagonalizable `A` puede descomponerse de la forma `PDP^-1`. En esta descomposici√≥n:\n",
            "\n",
            "*   `D` es una matriz diagonal que tiene los valores propios (eigenvalues) de `A` en su diagonal.\n",
            "*   `P` es una matriz formada por los vectores propios (eigenvectors) correspondientes a esos valores propios.\n",
            "\n",
            "El contexto no describe un algoritmo general paso a paso para diagonalizar una matriz arbitraria (es decir, c√≥mo calcular `P` y `D` a partir de una matriz `A` que no es diagonal). El Ejemplo 4.14 ilustra la forma `A=PDP^-1` con una matriz `A` que ya es diagonal y muestra c√≥mo se obtienen sus valores y vectores propios para formar `P` y `D`. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 10\n",
            "\n",
            "Seg√∫n el contexto proporcionado, una matriz diagonalizable `A` puede descomponerse de la forma `PDP^-1`. En esta descomposici√≥n:\n",
            "\n",
            "*   `D` es una matriz diagonal que tiene los valores propios (eigenvalues) de `A` en su diagonal.\n",
            "*   `P` es una matriz formada por los vectores propios (eigenvectors) correspondientes a esos valores propios.\n",
            "\n",
            "El contexto no describe un algoritmo general paso a paso para diagonalizar una matriz arbitraria (es decir, c√≥mo calcular `P` y `D` a partir de una matriz `A` que no es diagonal). El Ejemplo 4.14 ilustra la forma `A=PDP^-1` con una matriz `A` que ya es diagonal y muestra c√≥mo se obtienen sus valores y vectores propios para formar `P` y `D`. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "k (chunks recuperados): 10\n",
            "\n",
            "Seg√∫n el contexto proporcionado, una matriz diagonalizable $A$ puede descomponerse de la forma $A = PDP^{-1}$ (o $A = PDP^t$ si es sim√©trica y se usa una base ortonormal de vectores propios).\n",
            "\n",
            "Para diagonalizar una matriz $A$:\n",
            "*   La matriz $D$ es una matriz diagonal que contiene los valores propios de $A$ en su diagonal.\n",
            "*   La matriz $P$ es una matriz cuyas columnas son los vectores propios correspondientes a los valores propios en $D$.\n",
            "\n",
            "El \"Ejemplo 4.14\" ilustra este proceso:\n",
            "Se calcula la matriz diagonal $D$ a partir de los valores propios de $A$ (en el ejemplo, $D = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$).\n",
            "Se determinan los espacios propios y una base de vectores propios (en el ejemplo, $B_0 = \\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} \\}$), que luego se utilizan para formar la matriz $P$ (en el ejemplo, $P = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$).\n",
            "Finalmente, se muestra la descomposici√≥n de $A$ como $P D P^{-1}$.\n",
            "\n",
            "En resumen, la diagonalizaci√≥n implica encontrar los valores y vectores propios de la matriz para construir las matrices $D$ y $P$ que permiten la descomposici√≥n $A = PDP^{-1}$. \n",
            "\n",
            "########################################################################################################################\n",
            "AN√ÅLISIS: TIPO DE B√öSQUEDA\n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tipo de b√∫squeda: semantic\n",
            "\n",
            "Seg√∫n el contexto proporcionado, una matriz diagonalizable $A$ puede descomponerse de la forma $A = PDP^{-1}$ (o $A = PDP^t$ si es sim√©trica y se usa una base ortonormal de vectores propios).\n",
            "\n",
            "Para diagonalizar una matriz $A$:\n",
            "*   La matriz $D$ es una matriz diagonal que contiene los valores propios de $A$ en su diagonal.\n",
            "*   La matriz $P$ es una matriz cuyas columnas son los vectores propios correspondientes a los valores propios en $D$.\n",
            "\n",
            "El \"Ejemplo 4.14\" ilustra este proceso:\n",
            "Se calcula la matriz diagonal $D$ a partir de los valores propios de $A$ (en el ejemplo, $D = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$).\n",
            "Se determinan los espacios propios y una base de vectores propios (en el ejemplo, $B_0 = \\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} \\}$), que luego se utilizan para formar la matriz $P$ (en el ejemplo, $P = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$).\n",
            "Finalmente, se muestra la descomposici√≥n de $A$ como $P D P^{-1}$.\n",
            "\n",
            "En resumen, la diagonalizaci√≥n implica encontrar los valores y vectores propios de la matriz para construir las matrices $D$ y $P$ que permiten la descomposici√≥n $A = PDP^{-1}$. \n",
            "\n",
            "########################################################################################################################\n",
            "AN√ÅLISIS: TIPO DE B√öSQUEDA\n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tipo de b√∫squeda: semantic\n",
            "\n",
            "El contexto proporcionado explica que una matriz diagonalizable A puede descomponerse de la forma \"PDP‚Åª¬π\", donde D es una matriz diagonal. Tambi√©n menciona que para una matriz sim√©trica, se puede tomar una base ortonormal de vectores propios, y para esta base, la descomposici√≥n es \"PDP·µó\".\n",
            "\n",
            "Sin embargo, el contexto no describe expl√≠citamente los pasos o el algoritmo para diagonalizar una matriz, es decir, c√≥mo obtener las matrices P y D para una matriz A dada. El ejemplo 4.14 ilustra la relaci√≥n A = PDP‚Åª¬π utilizando una matriz A que ya es diagonal, y a partir de ella calcula sus valores y vectores propios, as√≠ como las matrices P y P‚Åª¬π. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tipo de b√∫squeda: keyword\n",
            "\n",
            "El contexto proporcionado explica que una matriz diagonalizable A puede descomponerse de la forma \"PDP‚Åª¬π\", donde D es una matriz diagonal. Tambi√©n menciona que para una matriz sim√©trica, se puede tomar una base ortonormal de vectores propios, y para esta base, la descomposici√≥n es \"PDP·µó\".\n",
            "\n",
            "Sin embargo, el contexto no describe expl√≠citamente los pasos o el algoritmo para diagonalizar una matriz, es decir, c√≥mo obtener las matrices P y D para una matriz A dada. El ejemplo 4.14 ilustra la relaci√≥n A = PDP‚Åª¬π utilizando una matriz A que ya es diagonal, y a partir de ella calcula sus valores y vectores propios, as√≠ como las matrices P y P‚Åª¬π. \n",
            "\n",
            "========================================================================================================================\n",
            "Pregunta: ¬øC√≥mo puedo diagonalizar una matriz?\n",
            "Tipo de b√∫squeda: keyword\n",
            "\n",
            "No tengo informaci√≥n suficiente en el contexto proporcionado para explicar c√≥mo diagonalizar una matriz. El contexto aborda la matriz representante de una transformaci√≥n lineal y sus propiedades, pero no el proceso de diagonalizaci√≥n de una matriz. \n",
            "\n",
            "########################################################################################################################\n",
            "Experimentos de sensibilidad completados.\n",
            "No tengo informaci√≥n suficiente en el contexto proporcionado para explicar c√≥mo diagonalizar una matriz. El contexto aborda la matriz representante de una transformaci√≥n lineal y sus propiedades, pero no el proceso de diagonalizaci√≥n de una matriz. \n",
            "\n",
            "########################################################################################################################\n",
            "Experimentos de sensibilidad completados.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Usamos una pregunta m√°s dif√≠cil que las de 2.1.4 para que pueda explayarse m√°s\n",
        "analysis_question = \"¬øC√≥mo puedo diagonalizar una matriz?\"\n",
        "\n",
        "def build_index_for_chunk_size(chunk_size, overlap=200):\n",
        "    \"\"\"\n",
        "    Reconstruye los chunks y sus embeddings para un tama√±o de chunk dado,\n",
        "    usando los textos originales `texts` y el mismo modelo de embeddings.\n",
        "    \"\"\"\n",
        "    local_chunks = []\n",
        "    for t in texts:\n",
        "        local_chunks.extend(split_text(t, chunk_size=chunk_size, overlap=overlap))\n",
        "\n",
        "    local_emb_matrix = np.array(embeddings_model.embed_documents(local_chunks))\n",
        "    return local_chunks, local_emb_matrix\n",
        "\n",
        "\n",
        "def retrieve_semantic(question, chunks_idx, emb_matrix_idx, k=5):\n",
        "    \"\"\"\n",
        "    B√∫squeda SEM√ÅNTICA: similitud de coseno entre embeddings.\n",
        "    \"\"\"\n",
        "    query_vec = np.array(embeddings_model.embed_query(question))\n",
        "\n",
        "    doc_norms = np.linalg.norm(emb_matrix_idx, axis=1)\n",
        "    q_norm = np.linalg.norm(query_vec) + 1e-10\n",
        "    sims = (emb_matrix_idx @ query_vec) / (doc_norms * q_norm + 1e-10)\n",
        "\n",
        "    top_k_idx = np.argsort(sims)[-k:][::-1]\n",
        "    return [chunks_idx[i] for i in top_k_idx]\n",
        "\n",
        "\n",
        "def _tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z√°√©√≠√≥√∫√º√±0-9\\s]\", \" \", text)\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def retrieve_keyword(question, chunks_idx, k=5):\n",
        "    \"\"\"\n",
        "    B√∫squeda L√âXICA: ranking por cantidad de palabras en com√∫n (muy simple).\n",
        "    No usa embeddings.\n",
        "    \"\"\"\n",
        "    q_tokens = set(_tokenize(question))\n",
        "    scores = []\n",
        "\n",
        "    for chunk in chunks_idx:\n",
        "        c_tokens = set(_tokenize(chunk))\n",
        "        scores.append(len(q_tokens & c_tokens))\n",
        "\n",
        "    scores = np.array(scores)\n",
        "    top_k_idx = np.argsort(scores)[-k:][::-1]\n",
        "    return [chunks_idx[i] for i in top_k_idx]\n",
        "\n",
        "\n",
        "def rag_with_index(question, chunks_idx, emb_matrix_idx=None, k=5, search_type=\"semantic\"):\n",
        "    \"\"\"\n",
        "    Versi√≥n de RAG que permite elegir:\n",
        "    - tama√±o de chunk (a trav√©s del √≠ndice que se le pasa),\n",
        "    - k (cantidad de chunks),\n",
        "    - tipo de b√∫squeda: 'semantic' o 'keyword'.\n",
        "    \"\"\"\n",
        "    if search_type == \"semantic\":\n",
        "        assert emb_matrix_idx is not None, \"Se requiere emb_matrix_idx para b√∫squeda sem√°ntica\"\n",
        "        relevant_chunks = retrieve_semantic(question, chunks_idx, emb_matrix_idx, k=k)\n",
        "    elif search_type == \"keyword\":\n",
        "        relevant_chunks = retrieve_keyword(question, chunks_idx, k=k)\n",
        "    else:\n",
        "        raise ValueError(\"search_type debe ser 'semantic' o 'keyword'\")\n",
        "\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    contents = [\n",
        "        \"Eres un asistente que responde preguntas usando exclusivamente el contexto proporcionado. \"\n",
        "        \"Si la informaci√≥n no est√° en el contexto, di expl√≠citamente que no tienes informaci√≥n suficiente.\",\n",
        "        f\"Contexto:\\n{context}\",\n",
        "        f\"Pregunta: {question}\",\n",
        "        \"Respuesta (en espa√±ol):\",\n",
        "    ]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=contents,\n",
        "    )\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 1) EFECTO DEL TAMA√ëO DEL CHUNK\n",
        "# =====================================================================\n",
        "\n",
        "print(\"#\" * 120)\n",
        "print(\"AN√ÅLISIS: TAMA√ëO DEL CHUNK\\n\")\n",
        "\n",
        "# Usamos varios tama√±os de chunk\n",
        "chunk_sizes = [500, 1000, 2000]\n",
        "answers_chunk_size = {}\n",
        "\n",
        "for cs in chunk_sizes:\n",
        "    print(\"=\" * 120)\n",
        "    print(f\"Pregunta: {analysis_question}\")\n",
        "    print(f\"Tama√±o de chunk: {cs}\\n\")\n",
        "\n",
        "    cs_chunks, cs_embs = build_index_for_chunk_size(chunk_size=cs, overlap=200)\n",
        "    ans = rag_with_index(analysis_question, cs_chunks, cs_embs, k=5, search_type=\"semantic\")\n",
        "    answers_chunk_size[cs] = ans\n",
        "    print(ans, \"\\n\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 2) EFECTO DE LA CANTIDAD DE CHUNKS RECUPERADOS (k)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"#\" * 120)\n",
        "print(\"AN√ÅLISIS: CANTIDAD DE CHUNKS k\\n\")\n",
        "\n",
        "# Usamos un tama√±o de chunk fijo\n",
        "base_chunks, base_embs = build_index_for_chunk_size(chunk_size=1000, overlap=200)\n",
        "\n",
        "# Ks a probar\n",
        "ks = [1, 3, 5, 10]\n",
        "answers_k = {}\n",
        "\n",
        "for k in ks:\n",
        "    print(\"=\" * 120)\n",
        "    print(f\"Pregunta: {analysis_question}\")\n",
        "    print(f\"k (chunks recuperados): {k}\\n\")\n",
        "\n",
        "    ans = rag_with_index(analysis_question, base_chunks, base_embs, k=k, search_type=\"semantic\")\n",
        "    answers_k[k] = ans\n",
        "    print(ans, \"\\n\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 3) EFECTO DEL TIPO DE B√öSQUEDA\n",
        "# =====================================================================\n",
        "\n",
        "print(\"#\" * 120)\n",
        "print(\"AN√ÅLISIS: TIPO DE B√öSQUEDA\\n\")\n",
        "\n",
        "# Tipos de b√∫squeda a probar\n",
        "search_types = [\"semantic\", \"keyword\"]\n",
        "answers_search_type = {}\n",
        "\n",
        "for st in search_types:\n",
        "    print(\"=\" * 120)\n",
        "    print(f\"Pregunta: {analysis_question}\")\n",
        "    print(f\"Tipo de b√∫squeda: {st}\\n\")\n",
        "\n",
        "    # Para b√∫squeda l√©xica no necesitamos emb_matrix_idx\n",
        "    if st == \"semantic\":\n",
        "        ans = rag_with_index(analysis_question, base_chunks, base_embs, k=5, search_type=st)\n",
        "    else:\n",
        "        ans = rag_with_index(analysis_question, base_chunks, None, k=5, search_type=st)\n",
        "\n",
        "    answers_search_type[st] = ans\n",
        "    print(ans, \"\\n\")\n",
        "\n",
        "print(\"#\" * 120)\n",
        "print(\"Experimentos de sensibilidad completados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJiPPM0giX8"
      },
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci√≥n anterior, en esta secci√≥n se busca habilitar **Agentes** para obtener informaci√≥n a trav√©s de tools y as√≠ responder la pregunta del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V47l7Mjfrk0N"
      },
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de b√∫squeda **Tavily**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,        # cu√°ntos resultados traer\n",
        "    search_depth=\"basic\", # lo mantenemos b√°sico\n",
        ")\n",
        "\n",
        "tavily_tool.name = \"tavily_search\"\n",
        "tavily_tool.description = (\n",
        "    \"Motor de b√∫squeda web en tiempo real. √ösalo para noticias, informaci√≥n reciente \"\n",
        "    \"o datos que no est√©n en Wikipedia.\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SonB1A-9rtRq"
      },
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ehJJpoqsr26-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "\n",
        "wiki_wrapper = WikipediaAPIWrapper(\n",
        "    lang=\"es\",         # Wikipedia en espa√±ol\n",
        "    top_k_results=3,   # m√°ximo 3 art√≠culos relevantes\n",
        "    doc_content_chars_max=4000,\n",
        ")\n",
        "\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wiki_wrapper)\n",
        "\n",
        "wikipedia_tool.name = \"wikipedia_search\"\n",
        "wikipedia_tool.description = (\n",
        "    \"Consulta a Wikipedia en espa√±ol. √ösalo para conocimiento enciclop√©dico, \"\n",
        "    \"definiciones, biograf√≠as y temas generales.\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUIMdX6r0ne"
      },
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg√∫rese que su agente responda en espa√±ol. Por √∫ltimo, guarde el agente en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pD1_n0wrsDI5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Cliente de Gemini\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "\n",
        "def decidir_tool(pregunta: str) -> str:\n",
        "    \"\"\"\n",
        "    Heur√≠stica simple:\n",
        "    - Tavily: preguntas sobre noticias, '√∫ltimas', a√±os recientes, 'hoy', 'reciente', 'noticias', etc.\n",
        "    - Wikipedia: preguntas enciclop√©dicas (por defecto).\n",
        "    \"\"\"\n",
        "    p = pregunta.lower()\n",
        "    # se√±ales de \"tema reciente / noticias\"\n",
        "    if any(\n",
        "        kw in p\n",
        "        for kw in [\"√∫ltimas\", \"ultimas\", \"hoy\", \"ayer\", \"reciente\", \"noticias\", \"2023\", \"2024\", \"2025\"]\n",
        "    ):\n",
        "        return \"tavily\"\n",
        "    # por defecto, enciclop√©dico\n",
        "    return \"wikipedia\"\n",
        "\n",
        "\n",
        "def agente_busqueda(pregunta: str) -> str:\n",
        "    \"\"\"\n",
        "    Agente que decide qu√© tool usar (Tavily o Wikipedia),\n",
        "    usa la tool para obtener contexto, y luego llama a Gemini\n",
        "    para generar la respuesta final en espa√±ol.\n",
        "    \"\"\"\n",
        "    tool = decidir_tool(pregunta)\n",
        "    print(f\"[AGENTE] Pregunta: {pregunta}\")\n",
        "    print(f\"[AGENTE] Tool elegida: {tool}\")\n",
        "\n",
        "    if tool == \"tavily\":\n",
        "        # Convertimos el resultado a JSON formateado para mejor legibilidad\n",
        "        raw_result = tavily_tool.run(pregunta)\n",
        "        context = json.dumps(raw_result, ensure_ascii=False, indent=2)\n",
        "    elif tool == \"wikipedia\":\n",
        "        context = wikipedia_tool.run(pregunta)\n",
        "    else:\n",
        "        context = \"\"\n",
        "\n",
        "    contents = [\n",
        "        \"Eres un asistente que responde SIEMPRE en espa√±ol.\",\n",
        "        \"A continuaci√≥n tienes contexto obtenido con una herramienta externa (web o Wikipedia).\",\n",
        "        \"Responde la pregunta usando ese contexto. Si el contexto no es suficiente, dilo expl√≠citamente.\",\n",
        "        f\"Contexto:\\n{context}\",\n",
        "        f\"Pregunta: {pregunta}\",\n",
        "        \"Respuesta (en espa√±ol):\",\n",
        "    ]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=contents,\n",
        "    )\n",
        "    return response.text.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKV0JxK3r-XG"
      },
      "source": [
        "#### **2.2.4 Verificaci√≥n de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y aseg√∫rese que el agente est√© ocupando correctamente las tools disponibles. ¬øEn qu√© casos el agente deber√≠a ocupar la tool de Tavily? ¬øEn qu√© casos deber√≠a ocupar la tool de Wikipedia?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Pqo2dsxvywW_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "[AGENTE] Pregunta: ¬øQui√©n es Gabriel Boric?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "RESPUESTA DEL AGENTE:\n",
            "\n",
            "Gabriel Boric Font es un pol√≠tico chileno, egresado de Derecho, nacido en Punta Arenas el 11 de febrero de 1986. Actualmente se desempe√±a como presidente de la Rep√∫blica de Chile desde el 11 de marzo de 2022, cargo que ocupar√° hasta el 11 de marzo de 2026.\n",
            "\n",
            "Previamente, fue diputado de la Rep√∫blica durante dos per√≠odos (2014-2018 y 2018-2022) y presidente de la Federaci√≥n de Estudiantes de la Universidad de Chile (FECh) entre 2011 y 2012, siendo uno de los l√≠deres de las movilizaciones estudiantiles de ese a√±o. Particip√≥ en la creaci√≥n del Frente Amplio y fund√≥ Convergencia Social.\n",
            "\n",
            "Fue electo presidente en la segunda vuelta de las elecciones de 2021, obteniendo el 55,8% de los votos. Es el presidente con el mayor n√∫mero de votos en la historia de Chile, el gobernante m√°s joven del mundo en ejercicio al asumir, el presidente m√°s joven en la historia de su pa√≠s, el primero nacido despu√©s del golpe de Estado de 1973 y el primer presidente originario de la Regi√≥n de Magallanes.\n",
            "\n",
            "====================================================================================================\n",
            "[AGENTE] Pregunta: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "RESPUESTA DEL AGENTE:\n",
            "\n",
            "Gabriel Boric Font es un pol√≠tico chileno, egresado de Derecho, nacido en Punta Arenas el 11 de febrero de 1986. Actualmente se desempe√±a como presidente de la Rep√∫blica de Chile desde el 11 de marzo de 2022, cargo que ocupar√° hasta el 11 de marzo de 2026.\n",
            "\n",
            "Previamente, fue diputado de la Rep√∫blica durante dos per√≠odos (2014-2018 y 2018-2022) y presidente de la Federaci√≥n de Estudiantes de la Universidad de Chile (FECh) entre 2011 y 2012, siendo uno de los l√≠deres de las movilizaciones estudiantiles de ese a√±o. Particip√≥ en la creaci√≥n del Frente Amplio y fund√≥ Convergencia Social.\n",
            "\n",
            "Fue electo presidente en la segunda vuelta de las elecciones de 2021, obteniendo el 55,8% de los votos. Es el presidente con el mayor n√∫mero de votos en la historia de Chile, el gobernante m√°s joven del mundo en ejercicio al asumir, el presidente m√°s joven en la historia de su pa√≠s, el primero nacido despu√©s del golpe de Estado de 1973 y el primer presidente originario de la Regi√≥n de Magallanes.\n",
            "\n",
            "====================================================================================================\n",
            "[AGENTE] Pregunta: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "RESPUESTA DEL AGENTE:\n",
            "\n",
            "El teorema de Pit√°goras es una relaci√≥n en geometr√≠a euclidiana entre los tres lados de un tri√°ngulo rect√°ngulo. Afirma que el √°rea del cuadrado cuyo lado es la hipotenusa (el lado opuesto al √°ngulo recto) es igual a la suma de las √°reas de los cuadrados cuyos lados son los catetos (los otros dos lados que no son la hipotenusa).\n",
            "\n",
            "En otras palabras, establece que, en todo tri√°ngulo recto, la longitud de la hipotenusa es igual a la ra√≠z cuadrada de la suma del √°rea de los cuadrados de las respectivas longitudes de los catetos. Matem√°ticamente, si 'a' y 'b' son las longitudes de los catetos y 'c' es la longitud de la hipotenusa, se cumple la relaci√≥n: a¬≤ + b¬≤ = c¬≤.\n",
            "\n",
            "====================================================================================================\n",
            "[AGENTE] Pregunta: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[AGENTE] Tool elegida: tavily\n",
            "RESPUESTA DEL AGENTE:\n",
            "\n",
            "El teorema de Pit√°goras es una relaci√≥n en geometr√≠a euclidiana entre los tres lados de un tri√°ngulo rect√°ngulo. Afirma que el √°rea del cuadrado cuyo lado es la hipotenusa (el lado opuesto al √°ngulo recto) es igual a la suma de las √°reas de los cuadrados cuyos lados son los catetos (los otros dos lados que no son la hipotenusa).\n",
            "\n",
            "En otras palabras, establece que, en todo tri√°ngulo recto, la longitud de la hipotenusa es igual a la ra√≠z cuadrada de la suma del √°rea de los cuadrados de las respectivas longitudes de los catetos. Matem√°ticamente, si 'a' y 'b' son las longitudes de los catetos y 'c' es la longitud de la hipotenusa, se cumple la relaci√≥n: a¬≤ + b¬≤ = c¬≤.\n",
            "\n",
            "====================================================================================================\n",
            "[AGENTE] Pregunta: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[AGENTE] Tool elegida: tavily\n",
            "RESPUESTA DEL AGENTE:\n",
            "\n",
            "Las √∫ltimas noticias sobre la inflaci√≥n en Chile para 2024 indican que cerr√≥ el a√±o en un 4,5%.\n",
            "\n",
            "Este valor se ubic√≥:\n",
            "*   Por debajo de las estimaciones del Banco Central, seg√∫n AP News.\n",
            "*   Por encima del rango de tolerancia del Banco Central, seg√∫n Reuters.\n",
            "\n",
            "En el √∫ltimo mes del a√±o, el √çndice de Precios al Consumidor (IPC) descendi√≥ 0,2% en diciembre.\n",
            "RESPUESTA DEL AGENTE:\n",
            "\n",
            "Las √∫ltimas noticias sobre la inflaci√≥n en Chile para 2024 indican que cerr√≥ el a√±o en un 4,5%.\n",
            "\n",
            "Este valor se ubic√≥:\n",
            "*   Por debajo de las estimaciones del Banco Central, seg√∫n AP News.\n",
            "*   Por encima del rango de tolerancia del Banco Central, seg√∫n Reuters.\n",
            "\n",
            "En el √∫ltimo mes del a√±o, el √çndice de Precios al Consumidor (IPC) descendi√≥ 0,2% en diciembre.\n"
          ]
        }
      ],
      "source": [
        "# Definimos algunas preguntas de prueba para el agente\n",
        "preguntas_prueba = [\n",
        "    \"¬øQui√©n es Gabriel Boric?\",\n",
        "    \"¬øQu√© es el teorema de Pit√°goras?\",\n",
        "    \"¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\",\n",
        "]\n",
        "\n",
        "# Ejecutamos el agente para cada pregunta de prueba\n",
        "for q in preguntas_prueba:\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    respuesta = agente_busqueda(q)\n",
        "    print(\"RESPUESTA DEL AGENTE:\\n\")\n",
        "    print(respuesta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El agente deber√≠a usar Tavily para datos recientes y wikipedia para datos m√°s hist√≥ricos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbDTYiogquv"
      },
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci√≥n es encapsular las funcionalidades creadas en una soluci√≥n multiagente con un **supervisor**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-iUfH0WvI6m"
      },
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la soluci√≥n RAG de la secci√≥n 2.1 y el agente de la secci√≥n 2.2 a *tools* (una tool por cada uno)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "pw1cfTtvv1AZ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "# Tool para la soluci√≥n RAG de los apuntes\n",
        "rag_tool = Tool(\n",
        "    name=\"rag_apuntes_matematicas\",\n",
        "    description=(\n",
        "        \"Usa los apuntes de MA1001, MA1002, MA1101 y MA1102 para responder \"\n",
        "        \"preguntas de an√°lisis y √°lgebra, usando RAG.\"\n",
        "    ),\n",
        "    func=lambda question: rag_chain(question, k=5),\n",
        ")\n",
        "\n",
        "# Tool para el agente de b√∫squeda (Tavily + Wikipedia)\n",
        "agente_web_tool = Tool(\n",
        "    name=\"agente_web_tavily_wikipedia\",\n",
        "    description=(\n",
        "        \"Usa Wikipedia y Tavily para responder preguntas generales, biogr√°ficas \"\n",
        "        \"y de noticias actuales.\"\n",
        "    ),\n",
        "    func=lambda question: agente_busqueda(question),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQYNjT_0vPCg"
      },
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yv2ZY0BAv1RD"
      },
      "outputs": [],
      "source": [
        "def supervisor(pregunta: str) -> str:\n",
        "    \"\"\"\n",
        "    Agente supervisor: decide si asignar la pregunta al RAG de apuntes\n",
        "    o al agente de b√∫squeda web (Tavily+Wikipedia).\n",
        "    \"\"\"\n",
        "    p = pregunta.lower()\n",
        "\n",
        "    # Heur√≠stica simple para reconocer preguntas \"de curso\" (apuntes)\n",
        "    palabras_mate = [\n",
        "        \"sucesi√≥n\", \"sucesiones\", \"l√≠mite\", \"limite\",\n",
        "        \"derivada\", \"integral\", \"matriz\", \"matrices\",\n",
        "        \"vector\", \"espacio vectorial\", \"serie\",\n",
        "        \"conjunto numerable\", \"ma1001\", \"ma1002\", \"ma1101\", \"ma1102\",\n",
        "    ]\n",
        "\n",
        "    if any(kw in p for kw in palabras_mate):\n",
        "        herramienta = rag_tool\n",
        "    else:\n",
        "        herramienta = agente_web_tool\n",
        "\n",
        "    print(f\"[SUPERVISOR] Pregunta: {pregunta}\")\n",
        "    print(f\"[SUPERVISOR] Tool seleccionada: {herramienta.name}\")\n",
        "\n",
        "    # Usamos invoke para ejecutar la tool elegida\n",
        "    return herramienta.invoke(pregunta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3zWlvyvY7K"
      },
      "source": [
        "#### **2.3.3 Verificaci√≥n de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. ¬øC√≥mo var√≠an las respuestas bajo este enfoque?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6_1t0zkgv1qW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øC√≥mo se define una matriz A de m filas y n columnas con coeficientes en un cuerpo K?\n",
            "[SUPERVISOR] Pregunta: ¬øC√≥mo se define una matriz A de m filas y n columnas con coeficientes en un cuerpo K?\n",
            "[SUPERVISOR] Tool seleccionada: rag_apuntes_matematicas\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Una matriz A de m filas y n columnas con coeficientes en un cuerpo K se denota como A = (aij), donde aij son los coeficientes en K. El conjunto de todas estas matrices se denomina Mmn(K).\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\n",
            "[SUPERVISOR] Pregunta: ¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\n",
            "[SUPERVISOR] Tool seleccionada: rag_apuntes_matematicas\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Una matriz A de m filas y n columnas con coeficientes en un cuerpo K se denota como A = (aij), donde aij son los coeficientes en K. El conjunto de todas estas matrices se denomina Mmn(K).\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\n",
            "[SUPERVISOR] Pregunta: ¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\n",
            "[SUPERVISOR] Tool seleccionada: rag_apuntes_matematicas\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Sea (sn) una sucesi√≥n. Sea œÜ:N‚ÜíN una funci√≥n estrictamente creciente. Se llama subsucesi√≥n de sn generada por œÜ, a la sucesi√≥n (un), definida por: un=sœÜ(n).\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øQu√© significa que un conjunto sea numerable?\n",
            "[SUPERVISOR] Pregunta: ¬øQu√© significa que un conjunto sea numerable?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øQu√© significa que un conjunto sea numerable?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Sea (sn) una sucesi√≥n. Sea œÜ:N‚ÜíN una funci√≥n estrictamente creciente. Se llama subsucesi√≥n de sn generada por œÜ, a la sucesi√≥n (un), definida por: un=sœÜ(n).\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øQu√© significa que un conjunto sea numerable?\n",
            "[SUPERVISOR] Pregunta: ¬øQu√© significa que un conjunto sea numerable?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øQu√© significa que un conjunto sea numerable?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Un conjunto se dice que es numerable (o contable) cuando es finito o cuando existe una biyecci√≥n entre este conjunto y el conjunto de los n√∫meros naturales. En otras palabras, es un conjunto o bien finito o bien del mismo tama√±o que los n√∫meros naturales.\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øQui√©n es Gabriel Boric?\n",
            "[SUPERVISOR] Pregunta: ¬øQui√©n es Gabriel Boric?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øQui√©n es Gabriel Boric?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Un conjunto se dice que es numerable (o contable) cuando es finito o cuando existe una biyecci√≥n entre este conjunto y el conjunto de los n√∫meros naturales. En otras palabras, es un conjunto o bien finito o bien del mismo tama√±o que los n√∫meros naturales.\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øQui√©n es Gabriel Boric?\n",
            "[SUPERVISOR] Pregunta: ¬øQui√©n es Gabriel Boric?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øQui√©n es Gabriel Boric?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Gabriel Boric Font es un pol√≠tico chileno, egresado de Derecho. Naci√≥ en Punta Arenas el 11 de febrero de 1986. Actualmente, se desempe√±a como presidente de la Rep√∫blica de Chile desde el 11 de marzo de 2022, cargo que ocupar√° hasta el 11 de marzo de 2026.\n",
            "\n",
            "Previamente, fue diputado de la Rep√∫blica en los periodos legislativos 2014-2018 y 2018-2022. Como estudiante, fue presidente de la Federaci√≥n de Estudiantes de la Universidad de Chile (FECh) entre 2011 y 2012, y uno de los principales dirigentes de las movilizaciones estudiantiles de 2011.\n",
            "\n",
            "Particip√≥ en la creaci√≥n del Frente Amplio y fue nominado como candidato presidencial de Convergencia Social. Tras ganar unas primarias, se convirti√≥ en el candidato de la coalici√≥n Apruebo Dignidad y fue electo presidente el 19 de diciembre de 2021 con el 55,8 % de los votos. Se convirti√≥ en el presidente con el mayor n√∫mero de votos en la historia de Chile.\n",
            "\n",
            "Con treinta y seis a√±os al asumir, fue el gobernante m√°s joven del mundo en ejercicio y el presidente m√°s joven en la historia de su pa√≠s, adem√°s de ser el primero nacido despu√©s del golpe de Estado de 1973 e integrante de la generaci√≥n milenial. Tambi√©n es el primer presidente originario de la Regi√≥n de Magallanes.\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[SUPERVISOR] Pregunta: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Gabriel Boric Font es un pol√≠tico chileno, egresado de Derecho. Naci√≥ en Punta Arenas el 11 de febrero de 1986. Actualmente, se desempe√±a como presidente de la Rep√∫blica de Chile desde el 11 de marzo de 2022, cargo que ocupar√° hasta el 11 de marzo de 2026.\n",
            "\n",
            "Previamente, fue diputado de la Rep√∫blica en los periodos legislativos 2014-2018 y 2018-2022. Como estudiante, fue presidente de la Federaci√≥n de Estudiantes de la Universidad de Chile (FECh) entre 2011 y 2012, y uno de los principales dirigentes de las movilizaciones estudiantiles de 2011.\n",
            "\n",
            "Particip√≥ en la creaci√≥n del Frente Amplio y fue nominado como candidato presidencial de Convergencia Social. Tras ganar unas primarias, se convirti√≥ en el candidato de la coalici√≥n Apruebo Dignidad y fue electo presidente el 19 de diciembre de 2021 con el 55,8 % de los votos. Se convirti√≥ en el presidente con el mayor n√∫mero de votos en la historia de Chile.\n",
            "\n",
            "Con treinta y seis a√±os al asumir, fue el gobernante m√°s joven del mundo en ejercicio y el presidente m√°s joven en la historia de su pa√≠s, adem√°s de ser el primero nacido despu√©s del golpe de Estado de 1973 e integrante de la generaci√≥n milenial. Tambi√©n es el primer presidente originario de la Regi√≥n de Magallanes.\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[SUPERVISOR] Pregunta: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øQu√© es el teorema de Pit√°goras?\n",
            "[AGENTE] Tool elegida: wikipedia\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "En matem√°ticas, el teorema de Pit√°goras es una relaci√≥n en geometr√≠a euclidiana entre los tres lados de un tri√°ngulo rect√°ngulo. Afirma que el √°rea del cuadrado cuyo lado es la hipotenusa (el lado opuesto al √°ngulo recto) es igual a la suma de las √°reas de los cuadrados cuyos lados son los catetos (los otros dos lados que no son la hipotenusa).\n",
            "\n",
            "Este teorema se puede escribir como una ecuaci√≥n que relaciona las longitudes de los lados 'a', 'b' y 'c'. Espec√≠ficamente, en todo tri√°ngulo recto, si hay catetos de longitud 'a' y 'b', y la medida de la hipotenusa es 'c', entonces se cumple la relaci√≥n: a¬≤ + b¬≤ = c¬≤. Tambi√©n se establece que la longitud de la hipotenusa es igual a la ra√≠z cuadrada de la suma del √°rea de los cuadrados de las respectivas longitudes de los catetos. Es la proposici√≥n m√°s conocida con nombre propio en la matem√°tica.\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[SUPERVISOR] Pregunta: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[AGENTE] Tool elegida: tavily\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "En matem√°ticas, el teorema de Pit√°goras es una relaci√≥n en geometr√≠a euclidiana entre los tres lados de un tri√°ngulo rect√°ngulo. Afirma que el √°rea del cuadrado cuyo lado es la hipotenusa (el lado opuesto al √°ngulo recto) es igual a la suma de las √°reas de los cuadrados cuyos lados son los catetos (los otros dos lados que no son la hipotenusa).\n",
            "\n",
            "Este teorema se puede escribir como una ecuaci√≥n que relaciona las longitudes de los lados 'a', 'b' y 'c'. Espec√≠ficamente, en todo tri√°ngulo recto, si hay catetos de longitud 'a' y 'b', y la medida de la hipotenusa es 'c', entonces se cumple la relaci√≥n: a¬≤ + b¬≤ = c¬≤. Tambi√©n se establece que la longitud de la hipotenusa es igual a la ra√≠z cuadrada de la suma del √°rea de los cuadrados de las respectivas longitudes de los catetos. Es la proposici√≥n m√°s conocida con nombre propio en la matem√°tica.\n",
            "\n",
            "========================================================================================================================\n",
            "PREGUNTA: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[SUPERVISOR] Pregunta: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[SUPERVISOR] Tool seleccionada: agente_web_tavily_wikipedia\n",
            "[AGENTE] Pregunta: ¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\n",
            "[AGENTE] Tool elegida: tavily\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Las √∫ltimas noticias sobre la inflaci√≥n en Chile en 2024 indican que cerr√≥ el a√±o en un 4,5%. Esta cifra estuvo por debajo de las estimaciones del Banco Central, aunque a√∫n se mantuvo por encima de su rango de tolerancia. En el √∫ltimo mes de 2024, el √çndice de Precios al Consumidor (IPC) de Chile descendi√≥ un 0,2% en diciembre. Para el 2025, el Banco Central estima que el IPC cierre en torno al 3,7%.\n",
            "\n",
            "RESPUESTA DEL SUPERVISOR:\n",
            "\n",
            "Las √∫ltimas noticias sobre la inflaci√≥n en Chile en 2024 indican que cerr√≥ el a√±o en un 4,5%. Esta cifra estuvo por debajo de las estimaciones del Banco Central, aunque a√∫n se mantuvo por encima de su rango de tolerancia. En el √∫ltimo mes de 2024, el √çndice de Precios al Consumidor (IPC) de Chile descendi√≥ un 0,2% en diciembre. Para el 2025, el Banco Central estima que el IPC cierre en torno al 3,7%.\n"
          ]
        }
      ],
      "source": [
        "# Preguntas de la secci√≥n 2.1.4 (RAG sobre apuntes)\n",
        "preguntas_rag = [\n",
        "    \"¬øC√≥mo se define una matriz A de m filas y n columnas con coeficientes en un cuerpo K?\",\n",
        "    \"¬øCu√°l es la definici√≥n de subsucesi√≥n de una sucesi√≥n (s_n)?\",\n",
        "    \"¬øQu√© significa que un conjunto sea numerable?\",\n",
        "]\n",
        "\n",
        "# Preguntas de la secci√≥n 2.2.4 (agente web)\n",
        "preguntas_agente = [\n",
        "    \"¬øQui√©n es Gabriel Boric?\",\n",
        "    \"¬øQu√© es el teorema de Pit√°goras?\",\n",
        "    \"¬øCu√°les han sido las √∫ltimas noticias sobre la inflaci√≥n en Chile 2024?\",\n",
        "]\n",
        "\n",
        "for q in preguntas_rag + preguntas_agente:\n",
        "    print(\"\\n\" + \"=\" * 120)\n",
        "    print(\"PREGUNTA:\", q)\n",
        "    respuesta = supervisor(q)\n",
        "    print(\"\\nRESPUESTA DEL SUPERVISOR:\\n\")\n",
        "    print(respuesta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      },
      "source": [
        "#### **2.3.4 An√°lisis (0.25 puntos)**\n",
        "\n",
        "¬øQu√© diferencias tiene este enfoque con la soluci√≥n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAUlJxqoLK5r"
      },
      "source": [
        "`escriba su respuesta ac√°`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      },
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es Sebasti√°n\"\n",
        "  - Respuesta esperada: \"Hola Sebasti√°n! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es Sebasti√°n\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci√≥n entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es v√°lido <u>s√≥lo para la secci√≥n 2 de Large Language Models.</u>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFc3jBT5g0kT"
      },
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav√©s de `gradio`, una librer√≠a especializada en el levantamiento r√°pido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librer√≠a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "T8TsvnCPbkIA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJBztEUovKsF"
      },
      "source": [
        "Luego s√≥lo deben ejecutar el siguiente c√≥digo e interactuar con la interfaz a trav√©s del notebook o del link generado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Z3KedQSvg1-n"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ChatInterface.__init__() got an unexpected keyword argument 'type'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[44], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.015\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m response[: i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatInterface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChatbot MDS7202\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pueden cambiar esto si lo desean\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHola! Soy un chatbot muy √∫til :)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# tambi√©n la descripci√≥n\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlaunch(\n\u001b[0;32m     26\u001b[0m         share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# pueden compartir el link a sus amig@s para que interactuen con su chat!\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m         )\n",
            "\u001b[1;31mTypeError\u001b[0m: ChatInterface.__init__() got an unexpected keyword argument 'type'"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  Funci√≥n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = ... # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy √∫til :)\", # tambi√©n la descripci√≥n\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq_HN9WPddaB"
      },
      "source": [
        "# Conclusi√≥n\n",
        "√âxito!\n",
        "<center>\n",
        "<img src =\"https://media.tenor.com/MRQgxcelAV8AAAAM/perry-the-platypus-phineas-and-ferb.gif\" width = 400 />"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
