{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "516acf1d6e9d4ddb9a8acdeb6b1cca14",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "-MGJGjPDimJI"
   },
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "befdb70375f04ab79952117eb63723e7",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "SN4W-_BNimJJ"
   },
   "source": [
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### üë®‚Äçüè´üë©‚Äçüè´ Cuerpo Docente:\n",
    "\n",
    "- Profesores: Diego Cortez, Gabriel Iturra\n",
    "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
    "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina\n",
    "\n",
    "### üë®‚Äçüíªüë©‚Äçüíª Estudiantes:\n",
    "- Estudiante n¬∞1:\n",
    "- Estudiante n¬∞2:\n",
    "\n",
    "_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GjshSnpjGcr"
   },
   "source": [
    "### **Instrucciones importantes**\n",
    "\n",
    "1. **Formato del informe**:  \n",
    "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
    "     - Estructura clara y ordenada.  \n",
    "     - C√≥digo acompa√±ado de explicaciones detalladas.  \n",
    "     - Resultados presentados de forma visual y anal√≠tica.  \n",
    "\n",
    "2. **Descuento por informes deficientes**:  \n",
    "   - Cualquier secci√≥n del informe que no tenga una explicaci√≥n adecuada o no respete el formato ser√° penalizada con un descuento en la nota. Esto incluye c√≥digo sin comentarios o an√°lisis que no sean coherentes con los resultados presentados.\n",
    "   - **Comentarios sin formatear de ChatGPT o herramientas similares ser√°n penalizados (e.g: \"Inserta tu modelo ac√°\", etc.)**\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.giphy.com/media/ZkIUY6LZJMwrSMQMWu/giphy.gif?cid=6c09b952msc755426bpsadn4sysofcpqczczi7x1pghd41sw&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=v\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73dd6ad576224431b010e7650d06156e",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "mMwIvE7AimJK"
   },
   "source": [
    "# üì¨ Entrega Parcial 3 (30% del Proyecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbrEry-nnsfs"
   },
   "source": [
    "### üì™ Fecha de Entrega: \n",
    "\n",
    "Esta entrega cuenta con 2 partes:\n",
    "\n",
    "- **Predicciones**: 1 de Diciembre, 2 de Diciembre, 3 de Diciembre, 4 de Diciembre\n",
    "- **Informe:** 8 de Diciembre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S9iswjPnxmu"
   },
   "source": [
    "## üìñ Enunciado\n",
    "\n",
    "Despu√©s de haber superado con √©xito la implementaci√≥n de sus flujos de trabajo con `Airflow`, el equipo **Deep Drinkers ü§ñ** ha demostrado que no solo sabe construir modelos, sino tambi√©n integrarlos en pipelines reales listos para producci√≥n.\n",
    "\n",
    "El equipo t√©cnico de **SodAI Drinks ü•§** ha quedado tan satisfecho con la automatizaci√≥n de sus procesos que ahora les ha encomendado una nueva, y final, misi√≥n:  \n",
    "- üìä **Evaluar la calidad real de sus modelos en un entorno m√°s desafiante** \n",
    "- üß† **Comunicar los hallazgos de forma clara y profesional frente a una comisi√≥n**.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.giphy.com/btbUGSHh3f6eBjbDfh.webp\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Predicciones\n",
    "<center>\n",
    "<img src=\"https://i.giphy.com/NTMxntb8rMzmbd1x97.webp\" width=\"500\" height=\"300\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Su *pipeline* automatizado debe demostrar que puede manejar datos reales en producci√≥n. **SodAI Drinks** ü•§ liberar√° *batches* de datos en fechas diferentes para evaluar si su sistema se adapta correctamente, los cuales simular√°n la llegada de informaci√≥n nueva (cada batch es una semana).\n",
    "\n",
    "Lo que debe funcionar autom√°ticamente:\n",
    "- **Ejecuci√≥n Automatizada**: Su DAG de `Airflow` debe ser capaz de procesar cada *batch* de datos de manera autom√°tica cuando est√© disponible.\n",
    "- **Monitoreo Continuo**: El *pipeline* debe evaluar la calidad de los datos entrantes y detectar posibles desviaciones respecto al conjunto original.\n",
    "- **Decisi√≥n de Reentrenamiento**: Bas√°ndose en los an√°lisis de *data drift* y m√©tricas de rendimiento, el sistema debe determinar autom√°ticamente si es necesario reentrenar el modelo.\n",
    "- **Tracking Completo**: Todas las ejecuciones, m√©tricas y decisiones deben quedar registradas en `MLFlow` para posterior an√°lisis.\n",
    "- **Generaci√≥n de Predicciones**: Para cada *batch* procesado, el sistema debe generar las predicciones correspondientes y almacenarlas de manera organizada.\n",
    "\n",
    "**IMPORTANTE: Es imperativo que guarden los resultados de su pipeline (m√©tricas, tracking, predicciones, etc) para su an√°lisis en la siguiente secci√≥n.**\n",
    "\n",
    "### üìåEntregable: Competencia en CodaLab\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.giphy.com/NomCzPIGoXs3EIq77v.webp\" width=\"300\" height=\"300\">\n",
    "</center>\n",
    "\n",
    "Como parte de esta entrega final, el equipo debe utilizar su pipeline entrenado para **generar predicciones en los nuevos conjuntos de datos mencionados anteriormente**.\n",
    "\n",
    "Estas predicciones deben:\n",
    "\n",
    "- Ser generadas directamente desde el *pipeline* previamente desarrollado.  \n",
    "- Guardarse en archivos `.csv` siguiendo el formato requerido.  \n",
    "- Subirse a la plataforma **CodaLab**, donde se realizar√° la evaluaci√≥n final.\n",
    "\n",
    "En CodaLab podr√°n:\n",
    "\n",
    "- Ver el rendimiento de su modelo frente a los de otros equipos.  \n",
    "- Obtener una puntuaci√≥n basada en la m√©trica definida del proyecto.  \n",
    "\n",
    "Cada set de predicciones debe ser publicado en CodaLab en las siguientes fechas:\n",
    "- **Predicciones 1 üìÖ** : 1 de Diciembre (Fecha de predicci√≥n: 01/01/25 - 05/01/25)\n",
    "    - Note que para este set de predicciones, s√≥lo tendr√°n acceso a los datos publicados en la Entrega 1.\n",
    "- **Predicciones 2 üìÖ** : 2 de Diciembre (Fecha de predicci√≥n: 06/01/25 - 12/01/25)\n",
    "- **Predicciones 3 üìÖ** : 3 de Diciembre (Fecha de predicci√≥n: 13/01/25 - 19/01/25)\n",
    "- **Predicciones 4 üìÖ** : 4 de Diciembre (Fecha de predicci√≥n: 20/01/25 - 26/01/25)\n",
    "\n",
    "Para simular la llegada de nuevos datos, se publicar√°n los siguientes conjuntos de datos:\n",
    "- **Batch 1 üìÖ** : 2 de Diciembre (Con datos realizados del per√≠odo 01/01/25 - 05/01/25)\n",
    "- **Batch 2 üìÖ** : 3 de Diciembre (Con datos realizados del per√≠odo 06/01/25 - 12/01/25)\n",
    "- **Batch 3 üìÖ** : 4 de Diciembre (Con datos realizados del per√≠odo 13/01/25 - 19/01/25)\n",
    "- **Batch 4 üìÖ** : 5 de Diciembre (Con datos realizados del per√≠odo 20/01/25 - 26/01/25)\n",
    "    - Note como este conjunto de datos se publica **despu√©s** de la competencia, por lo que s√≥lo les servir√° para la √∫ltima evaluaci√≥n requerida en el informe.\n",
    "\n",
    "**IMPORTANTE:** Subir los resultados a tiempo en las tres fechas es **<u>OBLIGATORIO</u>** para la evaluaci√≥n del desempe√±o final del equipo. **Por cada fecha en la que no se suban predicciones, se aplicar√° un descuento de 0.75 puntos (75 d√©cimas) sobre la nota de la Entrega 3.**\n",
    "\n",
    "### üéÅ Bonus [0.5 puntos]\n",
    "\n",
    "Como incentivo adicional, se premiar√° a los **3 equipos con mejor performance en la m√©trica F1** con **0.5 puntos de puntaje adicional** sobre la nota de la Entrega 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Informe: Performance del modelo [6.0 puntos]\n",
    "\n",
    "En esta secci√≥n se espera que el equipo analice de manera retrospectiva el performance de su modelo y saque conclusiones en funci√≥n de sus resultados. \n",
    "\n",
    "Para esto, tendr√°n que incurrir en 3 tipos de an√°lisis:\n",
    "\n",
    "- **Individual:** Deben evaluar el performance de su modelo tomando cada semana de forma aislada.\n",
    "\n",
    "- **Comparativo:** Deben evaluar el performance de su modelo *a trav√©s* de las semanas, comparando el desempe√±o entre las semanas e identificando posibles tendencias.\n",
    "    - Para esta parte se espera que generen gr√°ficos de tendencia y tablas comparativas para apoyar su an√°lisis.\n",
    "\n",
    "- **Conclusiones y Aprendizajes:** Deben escribir sus principales conclusiones y aprendizajes de este proyecto. \n",
    "\n",
    "A lo largo de esta secci√≥n, se espera que respondan preguntas como:\n",
    "\n",
    "1. ¬øC√≥mo variaron sus m√©tricas a lo largo de los distintos conjuntos de datos? \n",
    "2. ¬øEn qu√© momento el modelo tuvo su peor desempe√±o y por qu√©?\n",
    "3. ¬øDetectaron alg√∫n cambio significativo (drift) en la distribuci√≥n de los datos? ¬øC√≥mo lo identificaron?  \n",
    "4. ¬øTuvieron que reentrenar su modelo con los nuevos datos? ¬øPorqu√©? ¬øAyud√≥ esto al performance de su modelo?\n",
    "4. ¬øQu√© decisi√≥n t√©cnica (modelo, m√©trica, imputaci√≥n, etc.) tuvo m√°s impacto en los resultados?  \n",
    "5. ¬øQu√© hiperpar√°metro fue el m√°s importante para su modelo? \n",
    "5. ¬øQu√© variable fue m√°s influyente en las predicciones? ¬øC√≥mo lo interpretan? ¬øC√≥mo cambi√≥ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
    "6. ¬øQu√© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
    "7. ¬øQu√© limitaciones detectaron en su modelo o en los datos?  \n",
    "\n",
    "**IMPORTANTE: Se espera que en sus respuestas hagan referencia a los artefactos (m√©tricas, hiperpar√°metros, gr√°ficos de interpretabilidad, etc) que su pipeline genera.**\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.tenor.com/m/jyQ3SPT1htEAAAAd/i-love-this-performance-even-more-simon-cowell.gif\" width=\"300\" height=\"300\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå An√°lisis individual [3.0 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Funciones auxiliares para leer datos y calcular m√©tricas\n",
    "\n",
    "# Leer las predicciones desde un archivo CSV\n",
    "def _read_predictions(pred_path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(pred_path, header=None, names=[\"customer_id\", \"product_id\"])\n",
    "    except Exception:\n",
    "        df = pd.read_csv(pred_path)\n",
    "        df = df[[\"customer_id\", \"product_id\"]]\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "# Leer las referencias de verdad desde un archivo Parquet o CSV\n",
    "def _read_reference(truth_path: Path) -> pd.DataFrame:\n",
    "    if truth_path is None:\n",
    "        return None\n",
    "    truth = None\n",
    "    try:\n",
    "        truth = pd.read_parquet(truth_path)\n",
    "    except Exception:\n",
    "        alt_csv = Path(truth_path).with_suffix(\".csv\")\n",
    "        if alt_csv.exists():\n",
    "            truth = pd.read_csv(alt_csv)\n",
    "        else:\n",
    "            raise\n",
    "    truth = truth[[\"customer_id\", \"product_id\"]].drop_duplicates()\n",
    "    return truth\n",
    "\n",
    "# Calcular m√©tricas de precisi√≥n, recall y F1 basadas en conjuntos\n",
    "def _compute_set_f1(preds: pd.DataFrame, truth: pd.DataFrame):\n",
    "    pred_pairs = set(map(tuple, preds[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    truth_pairs = set(map(tuple, truth[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    tp = len(pred_pairs & truth_pairs)\n",
    "    fp = len(pred_pairs - truth_pairs)\n",
    "    fn = len(truth_pairs - pred_pairs)\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    return tp, fp, fn, precision, recall, f1, len(pred_pairs), len(truth_pairs)\n",
    "\n",
    "# Preparar los vectores y_true y y_pred para el informe de clasificaci√≥n\n",
    "def _ytrue_ypred_for_report(preds: pd.DataFrame, truth: pd.DataFrame):\n",
    "    pred_pairs = set(map(tuple, preds[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    truth_pairs = set(map(tuple, truth[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    universe = sorted(pred_pairs | truth_pairs)\n",
    "    y_true = np.array([1 if pair in truth_pairs else 0 for pair in universe])\n",
    "    y_pred = np.array([1 if pair in pred_pairs else 0 for pair in universe])\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Funci√≥n principal para evaluar las predicciones\n",
    "def eval_batch_predictions(pred_path: Path, truth_parquet: Path | None = None, with_report: bool = True):\n",
    "    preds = _read_predictions(pred_path)\n",
    "    if truth_parquet and (Path(truth_parquet).exists() or Path(truth_parquet).with_suffix(\".csv\").exists()):\n",
    "        truth = _read_reference(truth_parquet)\n",
    "        tp, fp, fn, p, r, f1, n_pred, n_truth = _compute_set_f1(preds, truth)\n",
    "        print(f\"Pares de predicci√≥n √∫nicos: {n_pred} | Pares de verdad √∫nicos: {n_truth}\")\n",
    "        print(f\"Verdaderos Positivos (TP): {tp} | Falsos Positivos (FP): {fp} | Falsos Negativos (FN): {fn}\")\n",
    "        print(f\"Precisi√≥n: {p:.6f} | Recall: {r:.6f} | F1: {f1:.6f}\")\n",
    "        if with_report:\n",
    "            y_true, y_pred = _ytrue_ypred_for_report(preds, truth)\n",
    "            print(\"\\nClassification Report (positivo=1, negativo=0):\")\n",
    "            print(classification_report(y_true, y_pred, digits=6))\n",
    "    else:\n",
    "        counts = preds.groupby(\"customer_id\").size()\n",
    "        print(f\"Filas: {len(preds)} | Clientes: {counts.size} | top-k medio: {counts.mean():.2f} | top-k m√°ximo: {counts.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 1 (01/01/25 - 05/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 5628 | Pares de verdad √∫nicos: 3264\n",
      "Verdaderos Positivos (TP): 1993 | Falsos Positivos (FP): 3635 | Falsos Negativos (FN): 1271\n",
      "Precisi√≥n: 0.354122 | Recall: 0.610600 | F1: 0.448268\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      3635\n",
      "           1   0.354122  0.610600  0.448268      3264\n",
      "\n",
      "    accuracy                       0.288882      6899\n",
      "   macro avg   0.177061  0.305300  0.224134      6899\n",
      "weighted avg   0.167540  0.288882  0.212081      6899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de Batch 1\n",
    "pred_batch1 = Path(\"predictions/predicciones_4.csv\")\n",
    "truth_batch1 = Path(\"data/batch_t1.parquet\")\n",
    "if pred_batch1.exists():\n",
    "    eval_batch_predictions(pred_batch1, truth_batch1, with_report=True)\n",
    "else:\n",
    "    print(\"Archivo de Batch 1 no encontrado:\", pred_batch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "- Cobertura: Las predicciones incluyen 5,628 pares √∫nicos frente a 3,264 pares reales.\n",
    "- Desempe√±o: F1 = 0.448; precisi√≥n moderada (0.354) y recall alto (0.611).\n",
    "- Lectura: El modelo privilegia recall (recupera muchos verdaderos) a costa de falsos positivos. Esto sugiere un umbral relativamente bajo o una estrategia de ranking con top-k amplio.\n",
    "- Implicancias: √ötil para no perder compras reales, pero incrementa carga operativa por recomendaciones irrelevantes. Ajustar top-k o mezcla de se√±ales puede mejorar precisi√≥n sin sacrificar demasiado recall.\n",
    "- Pr√≥ximo ajuste: bajar un poco el top-k o subir el umbral para mejorar precisi√≥n, cuidando no perder demasiado recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 2 (06/01/25 - 12/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 2918 | Pares de verdad √∫nicos: 5103\n",
      "Verdaderos Positivos (TP): 1630 | Falsos Positivos (FP): 1288 | Falsos Negativos (FN): 3473\n",
      "Precisi√≥n: 0.558602 | Recall: 0.319420 | F1: 0.406433\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      1288\n",
      "           1   0.558602  0.319420  0.406433      5103\n",
      "\n",
      "    accuracy                       0.255046      6391\n",
      "   macro avg   0.279301  0.159710  0.203217      6391\n",
      "weighted avg   0.446025  0.255046  0.324523      6391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de performance por batch (Batch 2)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Batch 2 ‚Üí Mejor predicci√≥n (CSV)\n",
    "pred_batch2 = Path(\"predictions/predicciones_batch_t1_adv_b.csv\")\n",
    "truth_batch2 = Path(\"data/batch_t2.parquet\")\n",
    "if pred_batch2.exists():\n",
    "    eval_batch_predictions(pred_batch2, truth_batch2, with_report=True)\n",
    "else:\n",
    "    print(\"Archivo de Batch 2 no encontrado:\", pred_batch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "- Cobertura: 2,918 pares predichos vs 5,103 pares reales.\n",
    "- Desempe√±o: F1 = 0.406; precisi√≥n 0.559 y recall 0.319.\n",
    "- Lectura: Mayor precisi√≥n que en Batch 1, pero recall disminuye. B√°sicamente ahora acertamos m√°s proporcionalmente (mayor precisi√≥n), pero dejamos pasar m√°s compras reales (menor recall). El sistema est√° m√°s conservador: recomienda menos y acierta m√°s proporcionalmente.\n",
    "- Implicancias: Buen control de falsos positivos; podr√≠a recuperar m√°s verdaderos ampliando top-k o agregando se√±ales de popularidad/recencia para explorar sin perder demasiado precisi√≥n.\n",
    "- Pr√≥ximo ajuste: subir un poco el top-k o bajar levemente el umbral para recuperar recall, manteniendo una precisi√≥n razonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "- Cobertura: 2,918 pares predichos vs 5,103 pares reales.\n",
    "- Desempe√±o: F1 = 0.406; precisi√≥n 0.559 y recall 0.319.\n",
    "- Lectura: Mayor precisi√≥n que en Batch 1, pero recall disminuye. El sistema est√° m√°s conservador: recomienda menos y acierta m√°s proporcionalmente.\n",
    "- Implicancias: Buen control de falsos positivos; podr√≠a recuperar m√°s verdaderos ampliando top-k o agregando se√±ales de popularidad/recencia para explorar sin perder demasiado precisi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 3 (13/01/25 - 19/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 4235 | Pares de verdad √∫nicos: 4922\n",
      "Verdaderos Positivos (TP): 2199 | Falsos Positivos (FP): 2036 | Falsos Negativos (FN): 2723\n",
      "Precisi√≥n: 0.519244 | Recall: 0.446770 | F1: 0.480288\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      2036\n",
      "           1   0.519244  0.446770  0.480288      4922\n",
      "\n",
      "    accuracy                       0.316039      6958\n",
      "   macro avg   0.259622  0.223385  0.240144      6958\n",
      "weighted avg   0.367307  0.316039  0.339750      6958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de performance por batch (Batch 3)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Batch 3 ‚Üí Mejor predicci√≥n (ZIP o CSV)\n",
    "pred_batch3 = Path(\"predictions/predicciones_batch_t2_adv_b.zip\")\n",
    "truth_batch3 = Path(\"data/batch_t3.parquet\")\n",
    "if pred_batch3.exists():\n",
    "    eval_batch_predictions(pred_batch3, truth_batch3, with_report=True)\n",
    "else:\n",
    "    alt_csv_3 = Path(\"predictions/predicciones_batch_t2_adv_b.csv\")\n",
    "    if alt_csv_3.exists():\n",
    "        eval_batch_predictions(alt_csv_3, truth_batch3, with_report=True)\n",
    "    else:\n",
    "        print(\"Archivo de Batch 3 no encontrado:\", pred_batch3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretaci√≥n de resultados:**\n",
    "\n",
    "- Cobertura: 4,235 pares predichos vs 4,922 reales.\n",
    "- Desempe√±o: F1 = 0.480; precisi√≥n 0.519 y recall 0.447.\n",
    "- Lectura: Mejor equilibrio entre precisi√≥n y recall respecto a los anteriores. Acierta m√°s y recupera una proporci√≥n mayor de verdaderos, es decir, se logr√≥ un balance mejor entre acertar y recuperar compras reales.\n",
    "- Implicancias: La combinaci√≥n actual (estrategia `adv_b`/mejoras recientes) parece estabilizar el trade-off. Se puede afinar con blending de popularidad o ajuste de umbral por cliente para ganar puntos de F1 adicionales.\n",
    "- Pr√≥ximo ajuste: afinar top-k por cliente seg√∫n probabilidad/score y revisar umbrales por segmento para sumar algunos puntos de F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 4 (20/01/25 - 26/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 4283 | Clientes: 1012 | top-k medio: 4.23 | top-k m√°ximo: 20\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de performance por batch (Batch 4)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Batch 4 ‚Üí Mejor predicci√≥n (ZIP o CSV)\n",
    "pred_batch4 = Path(\"predictions/predicciones_batch_t3_adv_hybrid2.zip\")\n",
    "truth_batch4 = Path(\"data/batch_t4.parquet\")\n",
    "if pred_batch4.exists():\n",
    "    eval_batch_predictions(pred_batch4, truth_batch4)\n",
    "else:\n",
    "    alt_csv_4 = Path(\"predictions/predicciones_batch_t3_adv_hybrid2.csv\")\n",
    "    if alt_csv_4.exists():\n",
    "        eval_batch_predictions(alt_csv_4, truth_batch4)\n",
    "    else:\n",
    "        print(\"Archivo de Batch 4 no encontrado:\", pred_batch4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå An√°lisis comparativo [2.0 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de m√©tricas por batch:\n",
      "     batch  precision   recall        f1      tp      fp      fn  n_pred  \\\n",
      "0  Batch 1   0.354122  0.61060  0.448268  1993.0  3635.0  1271.0  5628.0   \n",
      "1  Batch 2   0.558602  0.31942  0.406433  1630.0  1288.0  3473.0  2918.0   \n",
      "2  Batch 3   0.519244  0.44677  0.480288  2199.0  2036.0  2723.0  4235.0   \n",
      "3  Batch 4        NaN      NaN       NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "   n_truth  \n",
      "0   3264.0  \n",
      "1   5103.0  \n",
      "2   4922.0  \n",
      "3      NaN  \n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=precision<br>batch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "precision",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "precision",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Batch 1",
          "Batch 2",
          "Batch 3"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "vu8+WvCp1j8JfSvYEODhPxHGRGqmneA/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=recall<br>batch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "recall",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "recall",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Batch 1",
          "Batch 2",
          "Batch 3"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "dQMKCgqK4z/d47ZeYHHUPxuSfovfl9w/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=f1<br>batch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "f1",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "f1",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Batch 1",
          "Batch 2",
          "Batch 3"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "Ywp0tWyw3D++ZKwHAAPaP6SsFCcLvd4/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "M√©trica"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Tendencia de m√©tricas por batch"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "batch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# c√≥digo para realizar an√°lisis de resultados entre batchs\n",
    "\n",
    "# An√°lisis comparativo: consolidaci√≥n y tendencias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "\n",
    "# Reutilizamos las funciones definidas anteriormente: _read_predictions, _read_reference, _compute_set_f1\n",
    "\n",
    "def evaluate_batch_metrics(name: str, pred_path: Path, truth_path: Path | None):\n",
    "    if not pred_path.exists():\n",
    "        return {\"batch\": name, \"precision\": np.nan, \"recall\": np.nan, \"f1\": np.nan, \"tp\": np.nan, \"fp\": np.nan, \"fn\": np.nan, \"n_pred\": np.nan, \"n_truth\": np.nan}\n",
    "    if truth_path is None or (not Path(truth_path).exists() and not Path(truth_path).with_suffix(\".csv\").exists()):\n",
    "        # Sin ground truth a√∫n ‚Üí solo cobertura\n",
    "        preds = _read_predictions(pred_path)\n",
    "        counts = preds.groupby(\"customer_id\").size()\n",
    "        return {\"batch\": name, \"precision\": np.nan, \"recall\": np.nan, \"f1\": np.nan, \"tp\": np.nan, \"fp\": np.nan, \"fn\": np.nan, \"n_pred\": len(preds.drop_duplicates()), \"n_truth\": np.nan, \"clientes\": counts.size, \"topk_mean\": counts.mean(), \"topk_max\": counts.max()}\n",
    "    # Con ground truth ‚Üí m√©tricas completas\n",
    "    preds = _read_predictions(pred_path)\n",
    "    truth = _read_reference(truth_path)\n",
    "    tp, fp, fn, p, r, f1, n_pred, n_truth = _compute_set_f1(preds, truth)\n",
    "    return {\"batch\": name, \"precision\": p, \"recall\": r, \"f1\": f1, \"tp\": tp, \"fp\": fp, \"fn\": fn, \"n_pred\": n_pred, \"n_truth\": n_truth}\n",
    "\n",
    "# Paths de predicciones y truths\n",
    "pred_paths = {\n",
    "    \"Batch 1\": Path(\"predictions/predicciones_4.csv\"),\n",
    "    \"Batch 2\": Path(\"predictions/predicciones_batch_t1_adv_b.csv\"),\n",
    "    \"Batch 3\": Path(\"predictions/predicciones_batch_t2_adv_b.zip\"),\n",
    "    \"Batch 4\": Path(\"epredictions/predicciones_batch_t3_adv_hybrid2.zip\"),\n",
    "}\n",
    "truth_paths = {\n",
    "    \"Batch 1\": Path(\"data/batch_t1.parquet\"),\n",
    "    \"Batch 2\": Path(\"data/batch_t2.parquet\"),\n",
    "    \"Batch 3\": Path(\"data/batch_t3.parquet\"),\n",
    "    \"Batch 4\": Path(\"data/batch_t4.parquet\") if Path(\"entrega_3/data/batch_t4.parquet\").exists() else None,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name in [\"Batch 1\", \"Batch 2\", \"Batch 3\", \"Batch 4\"]:\n",
    "    rows.append(evaluate_batch_metrics(name, pred_paths[name], truth_paths[name]))\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "print(\"Resumen de m√©tricas por batch:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Gr√°fico de tendencias (se actualiza cuando Batch 4 tenga truth)\n",
    "plot_df = metrics_df.copy()\n",
    "plot_df = plot_df.dropna(subset=[\"f1\"])  # solo batches con F1 disponible\n",
    "fig = px.line(plot_df, x=\"batch\", y=[\"precision\", \"recall\", \"f1\"], markers=True,\n",
    "              title=\"Tendencia de m√©tricas por batch\")\n",
    "fig.update_layout(legend_title_text=\"M√©trica\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå Conclusiones y Aprendizajes [1.0 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Escriba aqu√≠ sus conclusiones y aprendizajes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Estructura de entrega\n",
    "\n",
    "Se espera que su entrega cuente con la siguiente estructura de carpetas:\n",
    "\n",
    "```bash\n",
    "entrega_3/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ informe.ipynb # Jupyter notebook con sus resultados\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ predictions/ # Carpeta con las predicciones para cada batch de datos\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ data/ # Carpeta con los datos realizados (lo que realmente ocurri√≥)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6rrqJ85tmz"
   },
   "source": [
    "Mucho √©xito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://gifdb.com/images/high/may-the-force-be-with-you-anakin-skywalker-n2g5o0pm4h6iylsx.gif\" width=\"400\" height=\"300\">\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_notebook_id": "2939a76dd7c14f7f948714e40aa8bd20",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
