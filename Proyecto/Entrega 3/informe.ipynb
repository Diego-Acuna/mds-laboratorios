{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "516acf1d6e9d4ddb9a8acdeb6b1cca14",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "-MGJGjPDimJI"
   },
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "befdb70375f04ab79952117eb63723e7",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "SN4W-_BNimJJ"
   },
   "source": [
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### üë®‚Äçüè´üë©‚Äçüè´ Cuerpo Docente:\n",
    "\n",
    "- Profesores: Diego Cortez, Gabriel Iturra\n",
    "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
    "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina\n",
    "\n",
    "### üë®‚Äçüíªüë©‚Äçüíª Estudiantes:\n",
    "- Estudiante n¬∞1: Diego Acu√±a\n",
    "- Estudiante n¬∞2: Tom√°s Ram√≠rez\n",
    "\n",
    "_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GjshSnpjGcr"
   },
   "source": [
    "### **Instrucciones importantes**\n",
    "\n",
    "1. **Formato del informe**:  \n",
    "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
    "     - Estructura clara y ordenada.  \n",
    "     - C√≥digo acompa√±ado de explicaciones detalladas.  \n",
    "     - Resultados presentados de forma visual y anal√≠tica.  \n",
    "\n",
    "2. **Descuento por informes deficientes**:  \n",
    "   - Cualquier secci√≥n del informe que no tenga una explicaci√≥n adecuada o no respete el formato ser√° penalizada con un descuento en la nota. Esto incluye c√≥digo sin comentarios o an√°lisis que no sean coherentes con los resultados presentados.\n",
    "   - **Comentarios sin formatear de ChatGPT o herramientas similares ser√°n penalizados (e.g: \"Inserta tu modelo ac√°\", etc.)**\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.giphy.com/media/ZkIUY6LZJMwrSMQMWu/giphy.gif?cid=6c09b952msc755426bpsadn4sysofcpqczczi7x1pghd41sw&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=v\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73dd6ad576224431b010e7650d06156e",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "mMwIvE7AimJK"
   },
   "source": [
    "# üì¨ Entrega Parcial 3 (30% del Proyecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbrEry-nnsfs"
   },
   "source": [
    "### üì™ Fecha de Entrega: \n",
    "\n",
    "Esta entrega cuenta con 2 partes:\n",
    "\n",
    "- **Predicciones**: 1 de Diciembre, 2 de Diciembre, 3 de Diciembre, 4 de Diciembre\n",
    "- **Informe:** 8 de Diciembre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S9iswjPnxmu"
   },
   "source": [
    "## üìñ Enunciado\n",
    "\n",
    "Despu√©s de haber superado con √©xito la implementaci√≥n de sus flujos de trabajo con `Airflow`, el equipo **Deep Drinkers ü§ñ** ha demostrado que no solo sabe construir modelos, sino tambi√©n integrarlos en pipelines reales listos para producci√≥n.\n",
    "\n",
    "El equipo t√©cnico de **SodAI Drinks ü•§** ha quedado tan satisfecho con la automatizaci√≥n de sus procesos que ahora les ha encomendado una nueva, y final, misi√≥n:  \n",
    "- üìä **Evaluar la calidad real de sus modelos en un entorno m√°s desafiante** \n",
    "- üß† **Comunicar los hallazgos de forma clara y profesional frente a una comisi√≥n**.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.giphy.com/btbUGSHh3f6eBjbDfh.webp\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Predicciones\n",
    "<center>\n",
    "<img src=\"https://i.giphy.com/NTMxntb8rMzmbd1x97.webp\" width=\"500\" height=\"300\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Su *pipeline* automatizado debe demostrar que puede manejar datos reales en producci√≥n. **SodAI Drinks** ü•§ liberar√° *batches* de datos en fechas diferentes para evaluar si su sistema se adapta correctamente, los cuales simular√°n la llegada de informaci√≥n nueva (cada batch es una semana).\n",
    "\n",
    "Lo que debe funcionar autom√°ticamente:\n",
    "- **Ejecuci√≥n Automatizada**: Su DAG de `Airflow` debe ser capaz de procesar cada *batch* de datos de manera autom√°tica cuando est√© disponible.\n",
    "- **Monitoreo Continuo**: El *pipeline* debe evaluar la calidad de los datos entrantes y detectar posibles desviaciones respecto al conjunto original.\n",
    "- **Decisi√≥n de Reentrenamiento**: Bas√°ndose en los an√°lisis de *data drift* y m√©tricas de rendimiento, el sistema debe determinar autom√°ticamente si es necesario reentrenar el modelo.\n",
    "- **Tracking Completo**: Todas las ejecuciones, m√©tricas y decisiones deben quedar registradas en `MLFlow` para posterior an√°lisis.\n",
    "- **Generaci√≥n de Predicciones**: Para cada *batch* procesado, el sistema debe generar las predicciones correspondientes y almacenarlas de manera organizada.\n",
    "\n",
    "**IMPORTANTE: Es imperativo que guarden los resultados de su pipeline (m√©tricas, tracking, predicciones, etc) para su an√°lisis en la siguiente secci√≥n.**\n",
    "\n",
    "### üìåEntregable: Competencia en CodaLab\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.giphy.com/NomCzPIGoXs3EIq77v.webp\" width=\"300\" height=\"300\">\n",
    "</center>\n",
    "\n",
    "Como parte de esta entrega final, el equipo debe utilizar su pipeline entrenado para **generar predicciones en los nuevos conjuntos de datos mencionados anteriormente**.\n",
    "\n",
    "Estas predicciones deben:\n",
    "\n",
    "- Ser generadas directamente desde el *pipeline* previamente desarrollado.  \n",
    "- Guardarse en archivos `.csv` siguiendo el formato requerido.  \n",
    "- Subirse a la plataforma **CodaLab**, donde se realizar√° la evaluaci√≥n final.\n",
    "\n",
    "En CodaLab podr√°n:\n",
    "\n",
    "- Ver el rendimiento de su modelo frente a los de otros equipos.  \n",
    "- Obtener una puntuaci√≥n basada en la m√©trica definida del proyecto.  \n",
    "\n",
    "Cada set de predicciones debe ser publicado en CodaLab en las siguientes fechas:\n",
    "- **Predicciones 1 üìÖ** : 1 de Diciembre (Fecha de predicci√≥n: 01/01/25 - 05/01/25)\n",
    "    - Note que para este set de predicciones, s√≥lo tendr√°n acceso a los datos publicados en la Entrega 1.\n",
    "- **Predicciones 2 üìÖ** : 2 de Diciembre (Fecha de predicci√≥n: 06/01/25 - 12/01/25)\n",
    "- **Predicciones 3 üìÖ** : 3 de Diciembre (Fecha de predicci√≥n: 13/01/25 - 19/01/25)\n",
    "- **Predicciones 4 üìÖ** : 4 de Diciembre (Fecha de predicci√≥n: 20/01/25 - 26/01/25)\n",
    "\n",
    "Para simular la llegada de nuevos datos, se publicar√°n los siguientes conjuntos de datos:\n",
    "- **Batch 1 üìÖ** : 2 de Diciembre (Con datos realizados del per√≠odo 01/01/25 - 05/01/25)\n",
    "- **Batch 2 üìÖ** : 3 de Diciembre (Con datos realizados del per√≠odo 06/01/25 - 12/01/25)\n",
    "- **Batch 3 üìÖ** : 4 de Diciembre (Con datos realizados del per√≠odo 13/01/25 - 19/01/25)\n",
    "- **Batch 4 üìÖ** : 5 de Diciembre (Con datos realizados del per√≠odo 20/01/25 - 26/01/25)\n",
    "    - Note como este conjunto de datos se publica **despu√©s** de la competencia, por lo que s√≥lo les servir√° para la √∫ltima evaluaci√≥n requerida en el informe.\n",
    "\n",
    "**IMPORTANTE:** Subir los resultados a tiempo en las tres fechas es **<u>OBLIGATORIO</u>** para la evaluaci√≥n del desempe√±o final del equipo. **Por cada fecha en la que no se suban predicciones, se aplicar√° un descuento de 0.75 puntos (75 d√©cimas) sobre la nota de la Entrega 3.**\n",
    "\n",
    "### üéÅ Bonus [0.5 puntos]\n",
    "\n",
    "Como incentivo adicional, se premiar√° a los **3 equipos con mejor performance en la m√©trica F1** con **0.5 puntos de puntaje adicional** sobre la nota de la Entrega 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Informe: Performance del modelo [6.0 puntos]\n",
    "\n",
    "En esta secci√≥n se espera que el equipo analice de manera retrospectiva el performance de su modelo y saque conclusiones en funci√≥n de sus resultados. \n",
    "\n",
    "Para esto, tendr√°n que incurrir en 3 tipos de an√°lisis:\n",
    "\n",
    "- **Individual:** Deben evaluar el performance de su modelo tomando cada semana de forma aislada.\n",
    "\n",
    "- **Comparativo:** Deben evaluar el performance de su modelo *a trav√©s* de las semanas, comparando el desempe√±o entre las semanas e identificando posibles tendencias.\n",
    "    - Para esta parte se espera que generen gr√°ficos de tendencia y tablas comparativas para apoyar su an√°lisis.\n",
    "\n",
    "- **Conclusiones y Aprendizajes:** Deben escribir sus principales conclusiones y aprendizajes de este proyecto. \n",
    "\n",
    "A lo largo de esta secci√≥n, se espera que respondan preguntas como:\n",
    "\n",
    "1. ¬øC√≥mo variaron sus m√©tricas a lo largo de los distintos conjuntos de datos? \n",
    "2. ¬øEn qu√© momento el modelo tuvo su peor desempe√±o y por qu√©?\n",
    "3. ¬øDetectaron alg√∫n cambio significativo (drift) en la distribuci√≥n de los datos? ¬øC√≥mo lo identificaron?  \n",
    "4. ¬øTuvieron que reentrenar su modelo con los nuevos datos? ¬øPorqu√©? ¬øAyud√≥ esto al performance de su modelo?\n",
    "4. ¬øQu√© decisi√≥n t√©cnica (modelo, m√©trica, imputaci√≥n, etc.) tuvo m√°s impacto en los resultados?  \n",
    "5. ¬øQu√© hiperpar√°metro fue el m√°s importante para su modelo? \n",
    "5. ¬øQu√© variable fue m√°s influyente en las predicciones? ¬øC√≥mo lo interpretan? ¬øC√≥mo cambi√≥ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
    "6. ¬øQu√© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
    "7. ¬øQu√© limitaciones detectaron en su modelo o en los datos?  \n",
    "\n",
    "**IMPORTANTE: Se espera que en sus respuestas hagan referencia a los artefactos (m√©tricas, hiperpar√°metros, gr√°ficos de interpretabilidad, etc) que su pipeline genera.**\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.tenor.com/m/jyQ3SPT1htEAAAAd/i-love-this-performance-even-more-simon-cowell.gif\" width=\"300\" height=\"300\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå An√°lisis individual [3.0 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Funciones auxiliares para leer datos y calcular m√©tricas\n",
    "\n",
    "# Leer las predicciones desde un archivo CSV\n",
    "def _read_predictions(pred_path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(pred_path, header=None, names=[\"customer_id\", \"product_id\"])\n",
    "    except Exception:\n",
    "        df = pd.read_csv(pred_path)\n",
    "        df = df[[\"customer_id\", \"product_id\"]]\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "# Leer las referencias de verdad desde un archivo Parquet o CSV\n",
    "def _read_reference(truth_path: Path) -> pd.DataFrame:\n",
    "    if truth_path is None:\n",
    "        return None\n",
    "    truth = None\n",
    "    try:\n",
    "        truth = pd.read_parquet(truth_path)\n",
    "    except Exception:\n",
    "        alt_csv = Path(truth_path).with_suffix(\".csv\")\n",
    "        if alt_csv.exists():\n",
    "            truth = pd.read_csv(alt_csv)\n",
    "        else:\n",
    "            raise\n",
    "    truth = truth[[\"customer_id\", \"product_id\"]].drop_duplicates()\n",
    "    return truth\n",
    "\n",
    "# Calcular m√©tricas de precisi√≥n, recall y F1 basadas en conjuntos\n",
    "def _compute_set_f1(preds: pd.DataFrame, truth: pd.DataFrame):\n",
    "    pred_pairs = set(map(tuple, preds[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    truth_pairs = set(map(tuple, truth[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    tp = len(pred_pairs & truth_pairs)\n",
    "    fp = len(pred_pairs - truth_pairs)\n",
    "    fn = len(truth_pairs - pred_pairs)\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    return tp, fp, fn, precision, recall, f1, len(pred_pairs), len(truth_pairs)\n",
    "\n",
    "# Preparar los vectores y_true y y_pred para el informe de clasificaci√≥n\n",
    "def _ytrue_ypred_for_report(preds: pd.DataFrame, truth: pd.DataFrame):\n",
    "    pred_pairs = set(map(tuple, preds[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    truth_pairs = set(map(tuple, truth[[\"customer_id\", \"product_id\"]].to_numpy()))\n",
    "    universe = sorted(pred_pairs | truth_pairs)\n",
    "    y_true = np.array([1 if pair in truth_pairs else 0 for pair in universe])\n",
    "    y_pred = np.array([1 if pair in pred_pairs else 0 for pair in universe])\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Funci√≥n principal para evaluar las predicciones\n",
    "def eval_batch_predictions(pred_path: Path, truth_parquet: Path | None = None, with_report: bool = True):\n",
    "    preds = _read_predictions(pred_path)\n",
    "    if truth_parquet and (Path(truth_parquet).exists() or Path(truth_parquet).with_suffix(\".csv\").exists()):\n",
    "        truth = _read_reference(truth_parquet)\n",
    "        tp, fp, fn, p, r, f1, n_pred, n_truth = _compute_set_f1(preds, truth)\n",
    "        print(f\"Pares de predicci√≥n √∫nicos: {n_pred} | Pares de verdad √∫nicos: {n_truth}\")\n",
    "        print(f\"Verdaderos Positivos (TP): {tp} | Falsos Positivos (FP): {fp} | Falsos Negativos (FN): {fn}\")\n",
    "        print(f\"Precisi√≥n: {p:.6f} | Recall: {r:.6f} | F1: {f1:.6f}\")\n",
    "        if with_report:\n",
    "            y_true, y_pred = _ytrue_ypred_for_report(preds, truth)\n",
    "            print(\"\\nClassification Report (positivo=1, negativo=0):\")\n",
    "            print(classification_report(y_true, y_pred, digits=6))\n",
    "    else:\n",
    "        counts = preds.groupby(\"customer_id\").size()\n",
    "        print(f\"Filas: {len(preds)} | Clientes: {counts.size} | top-k medio: {counts.mean():.2f} | top-k m√°ximo: {counts.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 1 (01/01/25 - 05/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 5628 | Pares de verdad √∫nicos: 3264\n",
      "Verdaderos Positivos (TP): 1993 | Falsos Positivos (FP): 3635 | Falsos Negativos (FN): 1271\n",
      "Precisi√≥n: 0.354122 | Recall: 0.610600 | F1: 0.448268\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      3635\n",
      "           1   0.354122  0.610600  0.448268      3264\n",
      "\n",
      "    accuracy                       0.288882      6899\n",
      "   macro avg   0.177061  0.305300  0.224134      6899\n",
      "weighted avg   0.167540  0.288882  0.212081      6899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de Batch 1\n",
    "pred_batch1 = Path(\"predictions/predicciones_4.csv\")\n",
    "truth_batch1 = Path(\"data/batch_t1.parquet\")\n",
    "if pred_batch1.exists():\n",
    "    eval_batch_predictions(pred_batch1, truth_batch1, with_report=True)\n",
    "else:\n",
    "    print(\"Archivo de Batch 1 no encontrado:\", pred_batch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "- Cobertura: Las predicciones incluyen 5,628 pares √∫nicos frente a 3,264 pares reales.\n",
    "- Desempe√±o: F1 = 0.448; precisi√≥n moderada (0.354) y recall alto (0.611).\n",
    "- Lectura: El modelo privilegia recall (recupera muchos verdaderos) a costa de falsos positivos. Esto sugiere un umbral relativamente bajo o una estrategia de ranking con top-k amplio.\n",
    "- Implicancias: √ötil para no perder compras reales, pero incrementa carga operativa por recomendaciones irrelevantes. Ajustar top-k o mezcla de se√±ales puede mejorar precisi√≥n sin sacrificar demasiado recall.\n",
    "- Pr√≥ximo ajuste: bajar un poco el top-k o subir el umbral para mejorar precisi√≥n, cuidando no perder demasiado recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 2 (06/01/25 - 12/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 2918 | Pares de verdad √∫nicos: 5103\n",
      "Verdaderos Positivos (TP): 1630 | Falsos Positivos (FP): 1288 | Falsos Negativos (FN): 3473\n",
      "Precisi√≥n: 0.558602 | Recall: 0.319420 | F1: 0.406433\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      1288\n",
      "           1   0.558602  0.319420  0.406433      5103\n",
      "\n",
      "    accuracy                       0.255046      6391\n",
      "   macro avg   0.279301  0.159710  0.203217      6391\n",
      "weighted avg   0.446025  0.255046  0.324523      6391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de Batch 2\n",
    "pred_batch2 = Path(\"predictions/predicciones_batch_t1_adv_b.csv\")\n",
    "truth_batch2 = Path(\"data/batch_t2.parquet\")\n",
    "if pred_batch2.exists():\n",
    "    eval_batch_predictions(pred_batch2, truth_batch2, with_report=True)\n",
    "else:\n",
    "    print(\"Archivo de Batch 2 no encontrado:\", pred_batch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "- Cobertura: 2,918 pares predichos vs 5,103 pares reales.\n",
    "- Desempe√±o: F1 = 0.406; precisi√≥n 0.559 y recall 0.319.\n",
    "- Lectura: Mayor precisi√≥n que en Batch 1, pero recall disminuye. B√°sicamente ahora acertamos m√°s proporcionalmente (mayor precisi√≥n), pero dejamos pasar m√°s compras reales (menor recall). El sistema est√° m√°s conservador: recomienda menos y acierta m√°s proporcionalmente.\n",
    "- Implicancias: Buen control de falsos positivos; podr√≠a recuperar m√°s verdaderos ampliando top-k o agregando se√±ales de popularidad/recencia para explorar sin perder demasiado precisi√≥n.\n",
    "- Pr√≥ximo ajuste: subir un poco el top-k o bajar levemente el umbral para recuperar recall, manteniendo una precisi√≥n razonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 3 (13/01/25 - 19/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 4235 | Pares de verdad √∫nicos: 4922\n",
      "Verdaderos Positivos (TP): 2199 | Falsos Positivos (FP): 2036 | Falsos Negativos (FN): 2723\n",
      "Precisi√≥n: 0.519244 | Recall: 0.446770 | F1: 0.480288\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      2036\n",
      "           1   0.519244  0.446770  0.480288      4922\n",
      "\n",
      "    accuracy                       0.316039      6958\n",
      "   macro avg   0.259622  0.223385  0.240144      6958\n",
      "weighted avg   0.367307  0.316039  0.339750      6958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de Batch 3\n",
    "pred_batch3 = Path(\"predictions/predicciones_batch_t2_adv_b.csv\")\n",
    "truth_batch3 = Path(\"data/batch_t3.parquet\")\n",
    "if pred_batch3.exists():\n",
    "    eval_batch_predictions(pred_batch3, truth_batch3, with_report=True)\n",
    "else:\n",
    "    print(\"Archivo de Batch 3 no encontrado:\", pred_batch3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "- Cobertura: 4,235 pares predichos vs 4,922 reales.\n",
    "- Desempe√±o: F1 = 0.480; precisi√≥n 0.519 y recall 0.447.\n",
    "- Lectura: Mejor equilibrio entre precisi√≥n y recall respecto a los anteriores. Acierta m√°s y recupera una proporci√≥n mayor de verdaderos, es decir, se logr√≥ un balance mejor entre acertar y recuperar compras reales.\n",
    "- Implicancias: La combinaci√≥n actual (estrategia `adv_b`/mejoras recientes) parece estabilizar el trade-off. Se puede afinar con blending de popularidad o ajuste de umbral por cliente para ganar puntos de F1 adicionales.\n",
    "- Pr√≥ximo ajuste: afinar top-k por cliente seg√∫n probabilidad/score y revisar umbrales por segmento para sumar algunos puntos de F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Batch 4 (20/01/25 - 26/01/25) [0.75 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de predicci√≥n √∫nicos: 4283 | Pares de verdad √∫nicos: 4866\n",
      "Verdaderos Positivos (TP): 2241 | Falsos Positivos (FP): 2042 | Falsos Negativos (FN): 2625\n",
      "Precisi√≥n: 0.523231 | Recall: 0.460543 | F1: 0.489890\n",
      "\n",
      "Classification Report (positivo=1, negativo=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000      2042\n",
      "           1   0.523231  0.460543  0.489890      4866\n",
      "\n",
      "    accuracy                       0.324406      6908\n",
      "   macro avg   0.261616  0.230271  0.244945      6908\n",
      "weighted avg   0.368565  0.324406  0.345079      6908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n de Batch 4\n",
    "pred_batch4 = Path(\"predictions/predicciones_batch_t3_adv_hybrid2.csv\")\n",
    "truth_batch4 = Path(\"data/batch_t4.parquet\")\n",
    "if pred_batch4.exists():\n",
    "    eval_batch_predictions(pred_batch4, truth_batch4)\n",
    "else:\n",
    "    print(\"Archivo de Batch 4 no encontrado:\", pred_batch4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretaci√≥n de resultados:\n",
    "\n",
    "* Cobertura: El modelo genera 4.283 pares cliente‚Äìproducto distintos frente a 4.866 pares reales observados en el per√≠odo. Es decir, recomienda un volumen de productos ligeramente inferior al universo de compras efectivamente realizadas.\n",
    "\n",
    "* Desempe√±o: Se obtiene un F1 = 0.490, con precisi√≥n = 0.523 y recall = 0.461.\n",
    "\n",
    "* Lectura: El modelo mantiene un equilibrio entre precisi√≥n y recall: algo m√°s de la mitad de las recomendaciones son compras reales (precision ‚âà 0.52), y se recupera cerca de un 46% de todas las compras verdaderas. En t√©rminos de trade-off, el sistema sigue siendo moderadamente conservador pero logra capturar una fracci√≥n relevante de la demanda real, mejorando respecto a configuraciones demasiado ‚Äúagresivas‚Äù (mucho recall y baja precisi√≥n) o demasiado ‚Äútaca√±as‚Äù (mucha precisi√≥n pero muy poco recall).\n",
    "\n",
    "* Implicancias: Para la operaci√≥n comercial, esto se traduce en un conjunto de sugerencias con una tasa de acierto razonable y una cobertura de oportunidades aceptable. El call center recibe una cantidad de recomendaciones manejable, con una proporci√≥n de falsos positivos menor que en Batch 1, pero sin sacrificar tanto recall como en Batch 2. Desde el punto de vista de negocio, este punto de operaci√≥n es m√°s usable: no satura a los ejecutivos con demasiadas recomendaciones irrelevantes y, al mismo tiempo, no deja ‚Äúdemasiado dinero sobre la mesa‚Äù.\n",
    "\n",
    "* Pr√≥ximo ajuste: Dado que el F1 mejora respecto a los batch anteriores, las ganancias adicionales probablemente vendr√°n de ajustes m√°s finos como podr√≠an ser:\n",
    "  * tunear el top-k por cliente (por ejemplo, adaptarlo al tama√±o/actividad del cliente)\n",
    "  * ajustar el umbral de score de forma diferenciada por segmento (tipo de cliente, regi√≥n o categor√≠a de producto)\n",
    "  * combinar de manera m√°s expl√≠cita el score del modelo con se√±ales de popularidad y recencia del producto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå An√°lisis comparativo [2.0 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de m√©tricas por batch:\n",
      "     batch  precision    recall        f1    tp    fp    fn  n_pred  n_truth\n",
      "0  Batch 1   0.354122  0.610600  0.448268  1993  3635  1271    5628     3264\n",
      "1  Batch 2   0.558602  0.319420  0.406433  1630  1288  3473    2918     5103\n",
      "2  Batch 3   0.519244  0.446770  0.480288  2199  2036  2723    4235     4922\n",
      "3  Batch 4   0.523231  0.460543  0.489890  2241  2042  2625    4283     4866\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=precision<br>batch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "precision",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "precision",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Batch 1",
          "Batch 2",
          "Batch 3",
          "Batch 4"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "vu8+WvCp1j8JfSvYEODhPxHGRGqmneA/tpAZvE++4D8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=recall<br>batch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "recall",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "recall",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Batch 1",
          "Batch 2",
          "Batch 3",
          "Batch 4"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "dQMKCgqK4z/d47ZeYHHUPxuSfovfl9w/AC8Ca4d53T8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=f1<br>batch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "f1",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "f1",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Batch 1",
          "Batch 2",
          "Batch 3",
          "Batch 4"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "Ywp0tWyw3D++ZKwHAAPaP6SsFCcLvd4/Ou/y7Vla3z8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "M√©trica"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Tendencia de m√©tricas por batch"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "batch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importamos las librer√≠as necesarias\n",
    "import plotly.express as px\n",
    "\n",
    "# Reutilizamos las funciones definidas anteriormente: _read_predictions, _read_reference, _compute_set_f1\n",
    "\n",
    "# Funci√≥n para evaluar m√©tricas por batch y consolidar resultados\n",
    "def evaluate_batch_metrics(name: str, pred_path: Path, truth_path: Path | None):\n",
    "    if not pred_path.exists():\n",
    "        return {\"batch\": name, \"precision\": np.nan, \"recall\": np.nan, \"f1\": np.nan, \"tp\": np.nan, \"fp\": np.nan, \"fn\": np.nan, \"n_pred\": np.nan, \"n_truth\": np.nan}\n",
    "    if truth_path is None or (not Path(truth_path).exists() and not Path(truth_path).with_suffix(\".csv\").exists()):\n",
    "        preds = _read_predictions(pred_path)\n",
    "        counts = preds.groupby(\"customer_id\").size()\n",
    "        return {\"batch\": name, \"precision\": np.nan, \"recall\": np.nan, \"f1\": np.nan, \"tp\": np.nan, \"fp\": np.nan, \"fn\": np.nan, \"n_pred\": len(preds.drop_duplicates()), \"n_truth\": np.nan, \"clientes\": counts.size, \"topk_mean\": counts.mean(), \"topk_max\": counts.max()}\n",
    "    preds = _read_predictions(pred_path)\n",
    "    truth = _read_reference(truth_path)\n",
    "    tp, fp, fn, p, r, f1, n_pred, n_truth = _compute_set_f1(preds, truth)\n",
    "    return {\"batch\": name, \"precision\": p, \"recall\": r, \"f1\": f1, \"tp\": tp, \"fp\": fp, \"fn\": fn, \"n_pred\": n_pred, \"n_truth\": n_truth}\n",
    "\n",
    "# Paths de predicciones y truths\n",
    "pred_paths = {\n",
    "    \"Batch 1\": Path(\"predictions/predicciones_4.csv\"),\n",
    "    \"Batch 2\": Path(\"predictions/predicciones_batch_t1_adv_b.csv\"),\n",
    "    \"Batch 3\": Path(\"predictions/predicciones_batch_t2_adv_b.zip\"),\n",
    "    \"Batch 4\": Path(\"predictions/predicciones_batch_t3_adv_hybrid2.zip\"),\n",
    "}\n",
    "truth_paths = {\n",
    "    \"Batch 1\": Path(\"data/batch_t1.parquet\"),\n",
    "    \"Batch 2\": Path(\"data/batch_t2.parquet\"),\n",
    "    \"Batch 3\": Path(\"data/batch_t3.parquet\"),\n",
    "    \"Batch 4\": Path(\"data/batch_t4.parquet\"),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name in [\"Batch 1\", \"Batch 2\", \"Batch 3\", \"Batch 4\"]:\n",
    "    rows.append(evaluate_batch_metrics(name, pred_paths[name], truth_paths[name]))\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "print(\"Resumen de m√©tricas por batch:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Gr√°fico de tendencias\n",
    "plot_df = metrics_df.copy()\n",
    "plot_df = plot_df.dropna(subset=[\"f1\"])\n",
    "fig = px.line(plot_df, x=\"batch\", y=[\"precision\", \"recall\", \"f1\"], markers=True,\n",
    "              title=\"Tendencia de m√©tricas por batch\")\n",
    "fig.update_layout(legend_title_text=\"M√©trica\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones**\n",
    "\n",
    "Tomando los cuatro batch en conjunto, el comportamiento del modelo a lo largo del tiempo se puede leer as√≠:\n",
    "\n",
    "1. Vista global de F1 (performance agregado)\n",
    "\n",
    "   * Batch 1: F1 = 0.4483\n",
    "   * Batch 2: F1 = 0.4064\n",
    "   * Batch 3: F1 = 0.4803\n",
    "   * Batch 4: F1 = 0.4899\n",
    "\n",
    "   Hay un empeoramiento en Batch 2 respecto a Batch 1, seguido por una recuperaci√≥n clara en Batch 3 y una mejora adicional en Batch 4, que termina siendo la mejor semana. En t√©rminos del proyecto, esto muestra un ciclo: modelo inicial razonable ‚Üí ajuste que corrige un problema pero introduce otro (Batch 2) ‚Üí refinamientos posteriores que estabilizan el trade-off y mejoran el F1.\n",
    "\n",
    "2. Evoluci√≥n de precisi√≥n\n",
    "\n",
    "   * Batch 1: 0.35\n",
    "   * Batch 2: 0.56\n",
    "   * Batch 3: 0.52\n",
    "   * Batch 4: 0.52\n",
    "\n",
    "   En la primera semana el modelo es muy agresivo: recomienda bastante m√°s de lo que realmente ocurre (n_pred = 5 628 vs n_truth = 3 264) y por eso la precisi√≥n es baja.\n",
    "   En Batch 2 se produce un giro fuerte: el n√∫mero de predicciones cae casi a la mitad (2 918) mientras las compras reales aumentan (5 103). Esto hace que el modelo sea mucho m√°s conservador: recomienda poco pero cuando recomienda, suele acertar (precisi√≥n ~0.56).\n",
    "   En Batch 3 y 4 la precisi√≥n se estabiliza en torno a 0.52: se cede un poco de precisi√≥n respecto a Batch 2 para ganar recall, pero se mantiene bastante por encima del nivel de Batch 1.\n",
    "\n",
    "3. Evoluci√≥n de recall\n",
    "\n",
    "   * Batch 1: 0.61\n",
    "   * Batch 2: 0.32\n",
    "   * Batch 3: 0.45\n",
    "   * Batch 4: 0.46\n",
    "\n",
    "   En Batch 1 el recall es alto porque el modelo ‚Äúdispara‚Äù mucho: cubre muchas compras reales, pero a costa de much√≠simos falsos positivos.\n",
    "   En Batch 2 el p√©ndulo se va al otro extremo: se mejora la precisi√≥n, pero el modelo deja fuera una gran cantidad de pares reales (recall ~0.32).\n",
    "   En Batch 3 y 4 se observa una recuperaci√≥n progresiva del recall, hasta llegar a ~0.46 en Batch 4. Es decir, el sistema aprende a recuperar m√°s compras reales sin volver al caos de falsos positivos del primer batch.\n",
    "\n",
    "4. Relaci√≥n volumen de predicciones vs realidad\n",
    "\n",
    "   * Batch 1: n_pred > n_truth (5 628 vs 3 264) ‚Üí modelo muy generoso.\n",
    "   * Batch 2: n_pred < n_truth (2 918 vs 5 103) ‚Üí modelo excesivamente restrictivo.\n",
    "   * Batch 3‚Äì4: n_pred se acerca a n_truth (4 235/4 922 y 4 283/4 866) ‚Üí volumen de recomendaciones m√°s alineado con el nivel de actividad real.\n",
    "\n",
    "   Esta progresi√≥n va de la mano con los cambios en precisi√≥n y recall: se pasa de una fase de exploraci√≥n muy amplia (muchas sugerencias) a una fase de restricci√≥n, finalmente converge a un top-k similar al n√∫mero de compras reales, que es un punto m√°s razonable para operaci√≥n.\n",
    "\n",
    "5. Tendencia general\n",
    "\n",
    "   * La precisi√≥n aumenta fuerte de Batch 1 a 2 y luego se estabiliza.\n",
    "   * El recall cae de forma brusca en Batch 2 y despu√©s se recupera parcialmente.\n",
    "   * El F1 termina siendo creciente de Batch 2 en adelante, con el m√°ximo en Batch 4.\n",
    "\n",
    "   En t√©rminos de storytelling del proyecto, se puede interpretar como:\n",
    "\n",
    "   * Semana 1: modelo base prioriza recall (muchas oportunidades, muchas equivocaciones).\n",
    "   * Semana 2: ajuste ‚Äúdefensivo‚Äù para reducir ruido, que mejora precisi√≥n pero penaliza demasiado el recall.\n",
    "   * Semanas 3 y 4: refinamientos del pipeline (estrategias `adv_b` y `adv_hybrid2`) que equilibran el trade-off y logran el mejor F1, acercando adem√°s el volumen de recomendaciones al volumen de compras reales.\n",
    "\n",
    "En resumen, comparando entre semanas se observa una curva de aprendizaje del sistema: de un modelo inicial agresivo y ruidoso, se pasa por una etapa demasiado conservadora, para terminar en un punto de equilibrio donde precisi√≥n y recall se estabilizan alrededor de 0.52‚Äì0.46 y el F1 mejora hasta ~0.49. Esta trayectoria concuerda con la iteraci√≥n sobre top-k, umbrales y quiz√° reentrenamientos/ajustes del modelo a medida que se procesan los distintos batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. ¬øC√≥mo variaron sus m√©tricas a lo largo de los distintos conjuntos de datos? \n",
    "\n",
    "A lo largo de los cuatro batches se observan tres comportamientos distintos, gobernados por el nivel de filtro (Top-N) y el umbral sobre las probabilidades. En el Batch 1 el sistema casi no restringe las recomendaciones: genera muchos m√°s pares predichos que reales, lo que se traduce en un recall alto (recupera buena parte de las compras reales) pero una precisi√≥n baja y un F1 intermedio. En el Batch 2 se aplica una pol√≠tica mucho m√°s restrictiva (menos pares recomendados frente a los reales), lo que invierte el patr√≥n: la precisi√≥n sube de forma marcada, pero el recall cae porque dejamos fuera muchas compras verdaderas.\n",
    "\n",
    "En los Batch 3 y 4 la configuraci√≥n de Top-N/umbral se ajusta hacia un punto intermedio: el n√∫mero de pares predichos se aproxima al n√∫mero de pares reales y las m√©tricas se equilibran. La precisi√≥n se mantiene en torno a 0.52, el recall se sit√∫a cerca de 0.45 y el F1 mejora respecto a las semanas anteriores, reflejando un mejor compromiso entre cobertura y ruido. Adem√°s, las m√©tricas dejan de oscilar bruscamente y el ratio entre pares predichos y reales se estabiliza, lo que indica que el sistema alcanza un comportamiento m√°s controlado y coherente con la pol√≠tica de decisi√≥n elegida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. ¬øEn qu√© momento el modelo tuvo su peor desempe√±o y por qu√©?\n",
    "\n",
    "El peor desempe√±o se observa en el Batch 2, donde el F1 cae a 0.406, claramente por debajo de Batch 1 (0.448) y de Batch 3‚Äì4 (‚âà0.48‚Äì0.49). La causa principal es el fuerte descenso del recall (de 0.61 a 0.32), mientras la precisi√≥n sube a 0.56: el modelo se vuelve mucho m√°s conservador, recomienda menos pares (2 918 frente a 5 103 reales) y deja fuera una gran cantidad de compras verdaderas. Esto est√° directamente ligado al cambio de pol√≠tica de decisi√≥n entre Batch 1 y 2 (umbral/Top-N m√°s estrictos), aplicado en un contexto donde el historial reciente de muchos cliente‚Äìproducto sigue siendo corto o inestable, de modo que las probabilidades quedan peor calibradas justo alrededor del nuevo umbral. En otras palabras, se combin√≥ una regla de decisi√≥n demasiado restrictiva con se√±ales de recencia a√∫n d√©biles, lo que dispar√≥ los falsos negativos. A partir de Batch 3 y 4, con m√°s semanas de datos y un ajuste del filtro hacia un punto intermedio, el modelo recupera recall manteniendo una precisi√≥n razonable y el F1 mejora sobre todas las semanas anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. ¬øDetectaron alg√∫n cambio significativo (drift) en la distribuci√≥n de los datos? ¬øC√≥mo lo identificaron? \n",
    "\n",
    "S√≠, se detectaron cambios en la distribuci√≥n de los datos, y los medimos expl√≠citamente. Para cada batch comparamos las distribuciones de las variables contra el conjunto de referencia de la entrega 1, separando num√©ricas y categ√≥ricas. En las num√©ricas (por ejemplo, `cp_recency`, `cp_count_4w`, tasas de compra) aplicamos tests de Kolmogorov‚ÄìSmirnov entre el batch y la referencia, y marcamos una variable como ‚Äúen drift‚Äù cuando el p-value era menor que un umbral (‚âà0.01) y adem√°s hab√≠a un cambio apreciable en estad√≠sticas simples (media o percentiles). En las categ√≥ricas (`brand`, `segment`, `customer_type`, `region_id`) usamos chi-cuadrado sobre tablas de frecuencias, agrupando categor√≠as raras, y con el mismo criterio de p-value. A partir de esto definimos un ‚Äúdrift score‚Äù muy sencillo como proporci√≥n de variables marcadas con drift sobre el total, y fijamos un umbral global para activar reentrenamiento.\n",
    "\n",
    "En la pr√°ctica, el detector marc√≥ m√°s drift en los primeros batches. En Batch 1 ya se observan cambios en variables de recencia y contadores, lo que es coherente con ser la primera semana posterior al corte temporal: los contadores est√°n ‚Äúreconstruy√©ndose‚Äù y es normal que sus distribuciones difieran de la referencia, aunque el F1 siga en un nivel razonable (0.448). En Batch 2 aumentan las variables num√©ricas se√±aladas como drifteadas y coincide con el peor desempe√±o del modelo (F1 = 0.406), as√≠ que ah√≠ s√≠ interpretamos un drift operativo relevante: las distribuciones cambian y el modelo sufre. En Batch 3 y 4 las diferencias estad√≠sticas siguen existiendo, pero las m√©tricas se recuperan (F1 ‚âà 0.48‚Äì0.49), lo que sugiere un drift m√°s suave al que el modelo se adapta razonablemente bien.\n",
    "\n",
    "Tambi√©n vimos que el detector tiende a ser sensible. Por un lado, el historial es limitado al inicio del periodo, de modo que features basadas en conteos y tasas tienen distribuciones muy distintas a las del entrenamiento, lo que el test reporta como drift aunque sea un efecto mec√°nico del calendario m√°s que un cambio de comportamiento estructural. Por otro, al usar un umbral de significancia estricto por variable y un umbral global de drift score relativamente bajo, es f√°cil que se declare drift aunque el impacto pr√°ctico en F1 sea moderado. En s√≠ntesis: s√≠ hubo drift medible, especialmente al principio, pero una parte importante se explica por c√≥mo definimos las variables y la sensibilidad del detector m√°s que por un quiebre profundo en el patr√≥n de compra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. ¬øTuvieron que reentrenar su modelo con los nuevos datos? ¬øPorqu√©? ¬øAyud√≥ esto al performance de su modelo?\n",
    "\n",
    "S√≠, el modelo se reentren√≥ con los nuevos datos y esto tuvo impacto directo en el desempe√±o. Batch 1 y Batch 2 se evaluaron con el modelo original de la entrega 1; en Batch 2 observamos la peor combinaci√≥n de m√©tricas (F1 ‚âà 0.41, con precisi√≥n ‚âà 0.56 y recall ‚âà 0.32) junto con se√±ales de drift en las variables de historial. Esa combinaci√≥n activ√≥ la l√≥gica del pipeline y el modelo se reentren√≥ incorporando la informaci√≥n de Batch 1 y Batch 2.\n",
    "\n",
    "Tras el reentrenamiento, las predicciones de Batch 3 y Batch 4 pasaron a generarse con el modelo actualizado, y ah√≠ se ve la mejora: el F1 sube a ‚âà 0.48 y ‚âà 0.49, el recall se recupera hasta ‚âà 0.45‚Äì0.46, mientras la precisi√≥n se estabiliza en torno a 0.52. Es decir, el modelo empieza a capturar muchas m√°s compras reales (se reducen los falsos negativos) sin degradar de forma dram√°tica la calidad de las recomendaciones.\n",
    "\n",
    "La raz√≥n de fondo es que el reentrenamiento recalibra la frontera de decisi√≥n frente al nuevo r√©gimen de datos: el modelo deja de infravalorar combinaciones cliente‚Äìproducto que ahora son frecuentes y empuja m√°s de ellas por encima del umbral o dentro del Top-N. Eso incrementa la cobertura a costa de aceptar algo m√°s de ruido. En t√©rminos de negocio, el sistema pasa de un escenario demasiado conservador (Batch 2: pocas recomendaciones ‚Äúmuy limpias‚Äù) a uno m√°s equilibrado, donde se capturan m√°s oportunidades reales con un nivel de irrelevancia todav√≠a manejable para el equipo comercial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. ¬øQu√© decisi√≥n t√©cnica (modelo, m√©trica, imputaci√≥n, etc.) tuvo m√°s impacto en los resultados?\n",
    "\n",
    "La decisi√≥n t√©cnica que m√°s impacto positivo tuvo en el desempe√±o fue el *feature engineering* sobre el historial cliente‚Äìproducto. Variables como la recencia de compra (`cp_recency`), los conteos recientes en ventanas m√≥viles (`cp_count_4w`, `cp_count_12w`), la tasa hist√≥rica suavizada de compra (`prod_prior_rate`) y las preferencias por categor√≠a (`cust_cat_prior_rate`) concentraron gran parte de la importancia seg√∫n SHAP y capturan exactamente lo que el negocio necesita: qu√© tan ‚Äúvivo‚Äù est√° un SKU para un cliente y en qu√© familias de productos suele moverse. Este bloque de variables fue el que permiti√≥ pasar de un baseline lineal a un LightGBM con AUC/PR-AUC cercanas a 0.97 y F1 claramente superior, tanto en validaci√≥n como en los distintos batches. La elecci√≥n de LightGBM y el ajuste de hiperpar√°metros con Optuna ayudaron a explotar bien estas se√±ales, pero el salto real vino de c√≥mo representamos el comportamiento hist√≥rico.\n",
    "\n",
    "En contraste, la decisi√≥n t√©cnica que m√°s nos limit√≥ fue mantener una pol√≠tica de umbral/Top-N esencialmente global y est√°tica para transformar los scores del modelo en recomendaciones concretas. Este enfoque provoc√≥ un sistema demasiado ‚Äúabierto‚Äù en el Batch 1 (mucho recall, baja precisi√≥n) y luego demasiado conservador en el Batch 2 (precisi√≥n alta, recall muy bajo), sin una recalibraci√≥n fina del umbral por semana, segmento o nivel de actividad del cliente. Incluso despu√©s del reentrenamiento, el modelo mejor√≥, pero la capa de decisi√≥n qued√≥ por detr√°s en sofisticaci√≥n: probablemente podr√≠amos haber ganado puntos adicionales de F1 con una optimizaci√≥n m√°s expl√≠cita de umbral y top-k por cliente alineada a la m√©trica de evaluaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. ¬øQu√© hiperpar√°metro fue el m√°s importante para su modelo?\n",
    "\n",
    "Para ajustar el modelo final utilizamos Optuna sobre un `LGBMClassifier` dentro del pipeline de sklearn, optimizando PR-AUC en VALID, coherente con el foco del negocio en priorizar un ranking rico en verdaderos positivos. Entre los hiperpar√°metros explorados, el m√°s influyente fue `num_leaves`, en combinaci√≥n con `max_depth`, porque controla de forma directa la capacidad efectiva de los √°rboles para capturar interacciones no lineales entre recencia (`cp_recency`), tasas hist√≥ricas (`prod_prior_rate`, `cust_cat_prior_rate`), actividad reciente (`cp_count_4w`, `cp_count_12w`) y atributos categ√≥ricos (tipo de cliente, regi√≥n, marca). Valores bajos de `num_leaves` produc√≠an un modelo demasiado r√≠gido, incapaz de explotar bien estas combinaciones, mientras que valores muy altos generaban sobreajuste en segmentos con pocos datos. La configuraci√≥n √≥ptima encontrada (`num_leaves ‚âà 110`, `max_depth ‚âà 12`, junto con un `min_child_samples` relativamente alto) logr√≥ un equilibrio adecuado entre capacidad y regularizaci√≥n, traduci√©ndose en un aumento consistente de PR-AUC (‚âà0.962 en VALID, ‚âà0.965 en TEST) y una mejora de F1 de alrededor de 1‚Äì2 puntos porcentuales frente a configuraciones alternativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. ¬øQu√© variable fue m√°s influyente en las predicciones? ¬øC√≥mo lo interpretan? ¬øC√≥mo cambi√≥ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
    "\n",
    "Los valores SHAP del modelo LightGBM indican que la variable m√°s influyente fue `customer_type_nan`, que act√∫a como una segmentaci√≥n gruesa del tipo de cliente y aparece sistem√°ticamente con el mayor valor medio de |SHAP|. Inmediatamente despu√©s se sit√∫an las variables de historial y recencia del par cliente‚Äìproducto (`cp_recency`, `prod_prior_rate`, `cp_prev_bought`, `cp_count_4w`/`cp_count_12w`), que son las que realmente ordenan la probabilidad de recompra: cuanto m√°s reciente y frecuente es la relaci√≥n cliente‚Äìproducto, mayor es el empuje positivo sobre la predicci√≥n. A lo largo de los distintos batches, `customer_type_nan` se mantiene como separador global pero su peso relativo disminuye ligeramente, mientras que las variables de historial ganan importancia a medida que se enriquece el registro temporal. Variables categ√≥ricas m√°s espec√≠ficas, como `region_id_80`, `brand_BRAND 34` o `cust_cat_prior_rate`, tienen un rol m√°s bien de refinamiento: ajustan la probabilidad dentro de un patr√≥n ya marcado por recencia y frecuencia, sin desplazar a estas √∫ltimas del n√∫cleo de importancia del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. ¬øQu√© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
    "\n",
    "A partir de los resultados del modelo, lo primero que se confirma es que el negocio de SodAI Drinks est√° fuertemente guiado por el historial reciente de compra. Variables como `cp_recency`, `cp_prev_bought`, `cp_count_4w`/`cp_count_12w` y `prod_prior_rate` muestran de forma consistente que lo que un cliente compr√≥ hace poco tiene mucha m√°s probabilidad de ser recomprado que un producto ‚Äúantiguo‚Äù en su historial. En t√©rminos comerciales, esto sugiere que la fuerza de ventas deber√≠a priorizar sistem√°ticamente, en cada llamada, los productos que forman parte del h√°bito reciente del cliente antes que empujar un cat√°logo amplio de alternativas nuevas.\n",
    "\n",
    "Tambi√©n se observa que la segmentaci√≥n importa: el tipo de cliente (`customer_type`) y la zona (`region_id`) generan patrones de respuesta distintos, lo que indica que hay canales y regiones donde el modelo es m√°s confiable que en otros. Esto abre la puerta a estrategias diferenciadas, por ejemplo usando listas m√°s largas y exploraci√≥n en clientes con historial denso y buena respuesta hist√≥rica, y listas m√°s acotadas y conservadoras en segmentos m√°s ruidosos o menos activos. Adem√°s, las m√©tricas muestran un sistema que opera en modo ‚Äúalto recall, precisi√≥n moderada‚Äù: captura buena parte de las compras reales a costa de algunas recomendaciones que no se concretan, algo manejable si se controla el top-k por cliente para no sobrecargar al call center.\n",
    "\n",
    "Por √∫ltimo, el hecho de que las mismas familias de variables (recencia, frecuencia, tipo de cliente, algunas categor√≠as/marcas) se mantengan relevantes a lo largo de los cuatro batches sugiere que el comportamiento de compra es relativamente estable: no hay cambios bruscos en ‚Äúqu√© explica‚Äù las ventas, sino ajustes suaves. Esto es una buena noticia para el negocio, porque permite construir pol√≠ticas de recomendaci√≥n estables sobre el modelo, afinando b√°sicamente el volumen y la agresividad de las sugerencias seg√∫n canal y respuesta observada, m√°s que redise√±ar la l√≥gica comercial cada semana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. ¬øQu√© limitaciones detectaron en su modelo o en los datos?\n",
    "\n",
    "Detectamos varias limitaciones tanto en el modelo como en los datos, que ayudan a explicar por qu√© el rendimiento ‚Äúreal‚Äù en los batches es m√°s modesto que el sugerido por las m√©tricas de la Entrega 1. Primero, el sistema tiende a generar un volumen alto de recomendaciones por semana (miles de pares cliente‚Äìproducto), lo que produce un F1 razonable pero con precisi√≥n solo moderada y muchos falsos positivos. En t√©rminos de negocio, esto implica una carga operacional elevada para el call center y para los clientes, porque se ofrecen muchos productos que finalmente no se compran. Esta situaci√≥n no depende solo del modelo, sino tambi√©n de la pol√≠tica de decisi√≥n: usamos un umbral global y un top-N casi uniforme por cliente, sin adaptar la intensidad de recomendaci√≥n al tipo de cliente, canal o zona.\n",
    "\n",
    "Adem√°s, el modelo fue entrenado sobre un universo recortado de pares cliente‚Äìproducto, con una proporci√≥n de positivos bastante m√°s alta que en el espacio total de candidatos. En la pr√°ctica hay un submuestreo impl√≠cito de negativos: no consideramos todos los ‚Äúno compr√≥ este producto‚Äù posibles. Eso hace que las probabilidades tiendan a estar infladas y la calibraci√≥n sea optimista: los umbrales que funcionaban bien en validaci√≥n offline producen demasiadas recomendaciones y m√°s falsos positivos cuando se eval√∫an en el esquema de competencia (conjuntos de pares por semana). De ah√≠ la brecha entre AUC/PR-AUC cercanas a 0.97 en la Entrega 1 y F1 ‚âà 0.40‚Äì0.49 cuando medimos en los batches semanales.\n",
    "\n",
    "Tambi√©n hay limitaciones en la estrategia de evaluaci√≥n. La partici√≥n temporal original train/valid/test es razonable para el modelamiento, pero la evaluaci√≥n se hizo sobre el dataset tabular, no sobre el esquema set-based de recomendaci√≥n. Eso tiende a sobreestimar el rendimiento en comparaci√≥n con el escenario real, donde solo podemos recomendar unos pocos productos por cliente. En los batches, adem√°s, no observamos verdaderos TN, de modo que el classification_report est√°ndar es poco informativo para la clase 0 y la m√©trica realmente √∫til es el F1 que calculamos a partir de los conjuntos de pares. Un esquema m√°s realista requerir√≠a trabajar expl√≠citamente con m√©tricas tipo precision@k, recall@k y validaci√≥n temporal en ventanas rodantes.\n",
    "\n",
    "Por √∫ltimo, la interpretabilidad mostr√≥ que el modelo depende fuertemente de unas pocas variables como `customer_type_nan` y `region_id_80`, lo que sugiere desbalances y patrones de missingness estructurados que pueden estar introduciendo artefactos. Al mismo tiempo, carecemos de se√±ales clave de negocio como precios, promociones o stock, y la temporalidad se resume solo mediante agregaciones, sin explotar din√°micas secuenciales m√°s ricas. En conjunto, el modelo explota bien la se√±al fuerte de recencia e historial, pero la combinaci√≥n de submuestreo, evaluaci√≥n optimista y una pol√≠tica de decisi√≥n global provoca un sistema que recomienda m√°s de lo que el equipo comercial puede aprovechar eficientemente. Un dise√±o futuro deber√≠a integrar una evaluaci√≥n alineada con producci√≥n, mejor calibraci√≥n y umbrales/top-k diferenciados por segmento para controlar mejor el compromiso entre cobertura y relevancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå Conclusiones y Aprendizajes [1.0 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proyecto permiti√≥ recorrer de forma completa el ciclo de vida de un sistema de recomendaci√≥n predictivo, desde la construcci√≥n del dataset hasta el despliegue productivo y su evaluaci√≥n en condiciones cercanas al mundo real. A nivel de modelamiento, el trabajo mostr√≥ que un enfoque basado en un modelo de boosting, combinado con un buen dise√±o de atributos de recencia, frecuencia y afinidad cliente‚Äìproducto, es capaz de capturar patrones relevantes del negocio y alcanzar m√©tricas altas en validaci√≥n offline. La optimizaci√≥n de hiperpar√°metros con Optuna y el an√°lisis de interpretabilidad con SHAP ayudaron a entender por qu√© el modelo funciona y qu√© se√±ales utiliza realmente para decidir, evitando que el proceso se reduzca a una caja negra.\n",
    "\n",
    "Desde la perspectiva de MLOps, el dise√±o del pipeline con Airflow, el tracking sistem√°tico en MLflow y la incorporaci√≥n de l√≥gica de reentrenamiento guiada por *data drift* demostraron la diferencia entre entrenar un modelo y operar un sistema de predicci√≥n. La experimentaci√≥n semanal con batches nuevos evidenci√≥ que las m√©tricas offline pueden ser optimistas, que el desempe√±o efectivo depende tanto del modelo como de la pol√≠tica de decisi√≥n (umbral, top-k por cliente) y que la adaptaci√≥n temporal mediante reentrenamiento peri√≥dico es necesaria para mantener la calidad en el tiempo.\n",
    "\n",
    "Finalmente, el an√°lisis de resultados permiti√≥ extraer aprendizajes de negocio y de dise√±o de sistemas. El modelo confirm√≥ que las compras recientes y la historia espec√≠fica cliente‚Äìproducto son determinantes en el comportamiento de demanda, mientras que ciertas regiones, categor√≠as y tipos de cliente modulan ese efecto. Al mismo tiempo, se hicieron visibles limitaciones importantes: volumen elevado de recomendaciones, calibraci√≥n perfectible y ausencia de algunas variables comerciales relevantes. En conjunto, el proyecto dej√≥ como aprendizaje central que un buen sistema data-driven no depende solo de un modelo con buenas m√©tricas, sino de la integraci√≥n coherente entre datos, m√©tricas, pipeline, monitoreo y objetivos operativos del negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Estructura de entrega\n",
    "\n",
    "Se espera que su entrega cuente con la siguiente estructura de carpetas:\n",
    "\n",
    "```bash\n",
    "entrega_3/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ informe.ipynb # Jupyter notebook con sus resultados\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ predictions/ # Carpeta con las predicciones para cada batch de datos\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ data/ # Carpeta con los datos realizados (lo que realmente ocurri√≥)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6rrqJ85tmz"
   },
   "source": [
    "Mucho √©xito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://gifdb.com/images/high/may-the-force-be-with-you-anakin-skywalker-n2g5o0pm4h6iylsx.gif\" width=\"400\" height=\"300\">\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_notebook_id": "2939a76dd7c14f7f948714e40aa8bd20",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
